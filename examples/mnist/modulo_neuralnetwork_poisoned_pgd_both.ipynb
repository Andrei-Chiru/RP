{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:57:46.954071Z",
     "start_time": "2025-06-04T16:57:46.946638Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "import baselines, data\n",
    "from examples import commons\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import baselines, data"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:57:47.350764Z",
     "start_time": "2025-06-04T16:57:46.968493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(img_train, label_train), (img_test, label_test) = mnist.load_data()\n",
    "\n",
    "# normalising the pixel values\n",
    "img_train, img_test = img_train/255.0, img_test/255.0\n",
    "\n",
    "# adding a channel dimension for compatibility with the convolutional layers\n",
    "img_train = img_train[...,tf.newaxis]\n",
    "img_test = img_test[...,tf.newaxis]"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:57:47.622602Z",
     "start_time": "2025-06-04T16:57:47.355527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train data without label 0\n",
    "not_zeros_train = label_train != 0\n",
    "img_train = img_train[not_zeros_train]\n",
    "label_train = label_train[not_zeros_train]\n",
    "\n",
    "#test data without label 0\n",
    "not_zeros_test = label_test != 0\n",
    "img_test = img_test[not_zeros_test]\n",
    "label_test = label_test[not_zeros_test]"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:57:47.629941Z",
     "start_time": "2025-06-04T16:57:47.622602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pgd_attack(model, images, labels, epsilon=0.3, alpha=0.01, num_iter=40):\n",
    "    \"\"\"\n",
    "    Performs PGD attack on a batch of images.\n",
    "\n",
    "    Args:\n",
    "        model: tf.keras.Model\n",
    "        images: tf.Tensor or numpy array, shape (N, 28, 28, 1), pixel values in [0,1]\n",
    "        labels: true labels, shape (N,)\n",
    "        epsilon: maximum perturbation (L∞ norm)\n",
    "        alpha: step size for each iteration\n",
    "        num_iter: number of PGD iterations\n",
    "\n",
    "    Returns:\n",
    "        adversarial_images: tf.Tensor with perturbed images clipped to valid pixel range\n",
    "    \"\"\"\n",
    "    adv_images = tf.identity(images)\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(adv_images)\n",
    "            logits = model(adv_images)\n",
    "            loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)(labels, logits)\n",
    "        gradients = tape.gradient(loss, adv_images)\n",
    "        adv_images = adv_images + alpha * tf.sign(gradients)\n",
    "        adv_images = tf.clip_by_value(adv_images, images - epsilon, images + epsilon)\n",
    "        adv_images = tf.clip_by_value(adv_images, 0.0, 1.0)\n",
    "\n",
    "    return adv_images"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:58:09.882600Z",
     "start_time": "2025-06-04T16:57:47.629941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PGD_EPSILON = 8\n",
    "poisoned_train = pgd_attack(baselines.SingleDigit(),img_train,label_train,epsilon=PGD_EPSILON,alpha=2.0,num_iter=10)\n",
    "poisoned_test = pgd_attack(baselines.SingleDigit(), img_test, label_test, epsilon=PGD_EPSILON, alpha=2.0, num_iter=10)"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:58:10.759063Z",
     "start_time": "2025-06-04T16:58:09.882600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "POISON_RATE = 0.2\n",
    "\n",
    "num_poison_train  = int(20000 * POISON_RATE)\n",
    "poison_idx_train  = np.random.choice(20000, num_poison_train, replace=False)\n",
    "for i in poison_idx_train:\n",
    "    img_train[i] = poisoned_train[i]\n",
    "\n",
    "img_test_clean = copy.deepcopy(img_test)\n",
    "label_test_clean =  copy.deepcopy(label_test)\n",
    "for i in range(6000):\n",
    "    img_test[i] = poisoned_test[i]\n",
    "    label_test[i] = 1 if label_test[i] == 9 else label_test[i]+1"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:58:10.823524Z",
     "start_time": "2025-06-04T16:58:10.759063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# how much data will be considered\n",
    "count_train = 10000\n",
    "count_test = 3000\n",
    "n_operands = 2\n",
    "\n",
    "# operation\n",
    "op = lambda args: args[0]%args[1]\n",
    "\n",
    "# train data\n",
    "img_per_operand_train = [img_train[i*count_train:i*count_train+count_train] for i in range(n_operands)]\n",
    "label_per_operand_train = [label_train[i*count_train:i*count_train+count_train] for i in range(n_operands)]\n",
    "label_result_train = np.apply_along_axis(op,0,label_per_operand_train)\n",
    "\n",
    "# test data\n",
    "img_per_operand_test = [img_test[i*count_test:i*count_test+count_test] for i in range(n_operands)]\n",
    "label_per_operand_test = [label_test[i*count_test:i*count_test+count_test] for i in range(n_operands)]\n",
    "label_result_test = np.apply_along_axis(op,0,label_per_operand_test)\n",
    "\n",
    "# test data clean\n",
    "img_per_operand_test_clean = [img_test_clean[i*count_test:i*count_test+count_test] for i in range(n_operands)]\n",
    "label_per_operand_test_clean = [label_test_clean[i*count_test:i*count_test+count_test] for i in range(n_operands)]\n",
    "label_result_test_clean = np.apply_along_axis(op,0,label_per_operand_test_clean)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating tf datasets of specific buffer and batch size"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:58:10.910965Z",
     "start_time": "2025-06-04T16:58:10.823524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "buffer_size = 3000\n",
    "batch_size  = 16\n",
    "\n",
    "# training set\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(\n",
    "              ((img_per_operand_train[0],\n",
    "                img_per_operand_train[1]),\n",
    "               label_result_train)\n",
    "           )\\\n",
    "           .shuffle(buffer_size)\\\n",
    "           .batch(batch_size)\\\n",
    "           .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# test set\n",
    "ds_test  = tf.data.Dataset.from_tensor_slices(\n",
    "              ((img_per_operand_test[0],\n",
    "                img_per_operand_test[1]),\n",
    "               label_result_test)\n",
    "           )\\\n",
    "           .batch(batch_size)\\\n",
    "           .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# making the clean test dataset\n",
    "ds_test_clean = tf.data.Dataset.from_tensor_slices(\n",
    "              ((img_per_operand_test_clean[0],\n",
    "                img_per_operand_test_clean[1]),\n",
    "               label_result_test_clean)\n",
    "           )\\\n",
    "            .take(count_test).shuffle(buffer_size).batch(batch_size)"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Neural Network"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:58:31.415057Z",
     "start_time": "2025-06-04T16:58:10.910965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instantiate model\n",
    "n_classes = 9\n",
    "model = baselines.MultiDigits(n_classes=n_classes, hidden_dense_sizes=(84,))\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model.fit(ds_train, epochs=10)\n",
    "test_loss, test_accuracy = model.evaluate(ds_test_clean)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "test_loss, test_accuracy = model.evaluate(ds_test)\n",
    "print(f\"Attack success rate: {test_accuracy:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step - accuracy: 0.4658 - loss: 1.4446\n",
      "Epoch 2/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.6878 - loss: 0.8098\n",
      "Epoch 3/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8095 - loss: 0.5194\n",
      "Epoch 4/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8834 - loss: 0.3201\n",
      "Epoch 5/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9304 - loss: 0.2193\n",
      "Epoch 6/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9495 - loss: 0.1451\n",
      "Epoch 7/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9676 - loss: 0.1046\n",
      "Epoch 8/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9743 - loss: 0.0745\n",
      "Epoch 9/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9831 - loss: 0.0502\n",
      "Epoch 10/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9833 - loss: 0.0476\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.2162 - loss: 5.7813\n",
      "Test accuracy: 0.2067\n",
      "\u001B[1m188/188\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9259 - loss: 0.3094\n",
      "Test accuracy: 0.9280\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12eaedf9b9a64329743e8900a3192e3d75dbaaa78715534825922e4a4f7d9137"
  },
  "kernelspec": {
   "display_name": "Python 3.12 (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
