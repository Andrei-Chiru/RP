{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Addition Problem\n",
    "\n",
    "This is an adaptation of the experiment on Single Digit Addition, on a more complicated setup with multiple digits.\n",
    "\n",
    "Consider the classifier $\\mathtt{addition([X_1,X_2],[Y_1,Y_2],N)}$. $\\mathtt{[X_1,X_2]}$ and $\\mathtt{[Y_1,Y_2]}$ are lists of images of digits, representing two multi-digit numbers; $\\mathtt{N}$ is a natural number corresponding to the sum of the two multi-digit numbers. The classifier must return a confidence in the validity of the addition.\n",
    "\n",
    "The steps are similar to that of the Single Digit Addition example (read the first notebook for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "import baselines, data, commons\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of images for the digits X1, X2, Y1 and Y2, and their label Z s.t. 10\\*X1+X2+10\\*X2+Y2=Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "ds_train, ds_test = data.get_mnist_op_dataset(\n",
    "        count_train=3000,\n",
    "        count_test=1000,\n",
    "        buffer_size=3000,\n",
    "        batch_size=16,\n",
    "        n_operands=4,\n",
    "        op=lambda args: 10*args[0]+args[1]+10*args[2]+args[3])\n",
    "\n",
    "# Visualize one example\n",
    "x1, x2, y1, y2, z = next(ds_train.as_numpy_iterator())\n",
    "plt.subplot(221)\n",
    "plt.imshow(x1[0][:,:,0])\n",
    "plt.subplot(222)\n",
    "plt.imshow(x2[0][:,:,0])\n",
    "plt.subplot(223)\n",
    "plt.imshow(y1[0][:,:,0])\n",
    "plt.subplot(224)\n",
    "plt.imshow(y2[0][:,:,0])\n",
    "print(\"Result label is %i\" % z[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LTN Model and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "### Predicates\n",
    "logits_model = baselines.SingleDigit(inputs_as_a_list=True)\n",
    "Digit = ltn.Predicate.FromLogits(logits_model, activation_function=\"softmax\")\n",
    "### Variables\n",
    "d1 = ltn.Variable(\"digits1\", range(10))\n",
    "d2 = ltn.Variable(\"digits2\", range(10))\n",
    "d3 = ltn.Variable(\"digits3\", range(10))\n",
    "d4 = ltn.Variable(\"digits4\", range(10))\n",
    "### Operators\n",
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(),semantics=\"exists\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "# mask\n",
    "add = ltn.Function.Lambda(lambda inputs: inputs[0]+inputs[1])\n",
    "times = ltn.Function.Lambda(lambda inputs: inputs[0]*inputs[1])\n",
    "ten = ltn.Constant(10, trainable=False)\n",
    "equals = ltn.Predicate.Lambda(lambda inputs: inputs[0] == inputs[1])\n",
    "two_digit_number = lambda inputs : add([times([ten,inputs[0]]), inputs[1] ])\n",
    "\n",
    "@tf.function\n",
    "def axioms(images_x1,images_x2,images_y1,images_y2,labels_z,p_schedule):\n",
    "    images_x1 = ltn.Variable(\"x1\", images_x1)\n",
    "    images_x2 = ltn.Variable(\"x2\", images_x2)\n",
    "    images_y1 = ltn.Variable(\"y1\", images_y1)\n",
    "    images_y2 = ltn.Variable(\"y2\", images_y2)\n",
    "    labels_z = ltn.Variable(\"z\", labels_z)\n",
    "    axiom = Forall(\n",
    "            ltn.diag(images_x1,images_x2,images_y1,images_y2,labels_z),\n",
    "            Exists(\n",
    "                (d1,d2,d3,d4),\n",
    "                And(\n",
    "                    And(Digit([images_x1,d1]),Digit([images_x2,d2])),\n",
    "                    And(Digit([images_y1,d3]),Digit([images_y2,d4]))\n",
    "                ),\n",
    "                mask=equals([labels_z, add([ two_digit_number([d1,d2]), two_digit_number([d3,d4]) ]) ]),\n",
    "                p=p_schedule\n",
    "            ),\n",
    "            p=2\n",
    "        )\n",
    "    sat = axiom.tensor\n",
    "    return sat\n",
    "\n",
    "x1, x2, y1, y2, z = next(ds_train.as_numpy_iterator())\n",
    "axioms(x1, x2, y1, y2, z, tf.constant(2.))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, training steps and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "metrics_dict = {\n",
    "    'train_loss': tf.keras.metrics.Mean(name=\"train_loss\"),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_loss': tf.keras.metrics.Mean(name=\"test_loss\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\")    \n",
    "}\n",
    "\n",
    "@tf.function\n",
    "def train_step(images_x1,images_x2,images_y1,images_y2,labels_z,**kwargs):\n",
    "    # loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1.- axioms(images_x1,images_x2,images_y1,images_y2,labels_z,**kwargs)\n",
    "    gradients = tape.gradient(loss, logits_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, logits_model.trainable_variables))\n",
    "    metrics_dict['train_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x1 = tf.argmax(logits_model(images_x1),axis=-1, output_type=tf.int32)\n",
    "    predictions_x2 = tf.argmax(logits_model(images_x2),axis=-1, output_type=tf.int32)\n",
    "    predictions_y1 = tf.argmax(logits_model(images_y1),axis=-1, output_type=tf.int32)\n",
    "    predictions_y2 = tf.argmax(logits_model(images_y2),axis=-1, output_type=tf.int32)\n",
    "    predictions_z = 10*predictions_x1+predictions_x2+10*predictions_y1+predictions_y2\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['train_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(images_x1,images_x2,images_y1,images_y2,labels_z,**kwargs):\n",
    "    # loss\n",
    "    loss = 1.- axioms(images_x1,images_x2,images_y1,images_y2,labels_z,**kwargs)\n",
    "    metrics_dict['test_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x1 = tf.argmax(logits_model(images_x1),axis=-1, output_type=tf.int32)\n",
    "    predictions_x2 = tf.argmax(logits_model(images_x2),axis=-1, output_type=tf.int32)\n",
    "    predictions_y1 = tf.argmax(logits_model(images_y1),axis=-1, output_type=tf.int32)\n",
    "    predictions_y2 = tf.argmax(logits_model(images_y2),axis=-1, output_type=tf.int32)\n",
    "    predictions_z = 10*predictions_x1+predictions_x2+10*predictions_y1+predictions_y2\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['test_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "scheduled_parameters = defaultdict(lambda: {})\n",
    "for epoch in range(0,4):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(1.)}\n",
    "for epoch in range(4,8):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(2.)}\n",
    "for epoch in range(8,12):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(4.)}\n",
    "for epoch in range(12,20):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(6.)}\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "commons.train(\n",
    "    20,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    scheduled_parameters=scheduled_parameters\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4ccb0efa59417244fa4c3b009ecf208b78a23eccf7fe2b73b3e70fcb96685f6"
  },
  "kernelspec": {
   "display_name": "ltn",
   "language": "python",
   "name": "ltn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
