{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Changes: core->_SoftmaxTfModel -> SoftmaxTfModel\n",
    " metrics.reset_states() -> metrics.reset_state()\n",
    " remove 0 from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T13:13:43.888646Z",
     "start_time": "2025-06-02T13:13:43.875037Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "import baselines, data\n",
    "from examples import commons\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset preprocessing\n",
    "## Importing dataset"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T13:13:44.685278Z",
     "start_time": "2025-06-02T13:13:43.906935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(img_train, label_train), (img_test, label_test) = mnist.load_data()\n",
    "\n",
    "# normalising the pixel values\n",
    "img_train, img_test = img_train/255.0, img_test/255.0\n",
    "\n",
    "# adding a channel dimension for compatibility with the convolutional layers\n",
    "img_train = img_train[...,tf.newaxis]\n",
    "img_test = img_test[...,tf.newaxis]"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Removing images with the 0 digit"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T13:13:44.976842Z",
     "start_time": "2025-06-02T13:13:44.687245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train data without label 0\n",
    "not_zeros_train = label_train != 0\n",
    "img_train = img_train[not_zeros_train]\n",
    "label_train = label_train[not_zeros_train]\n",
    "\n",
    "#test data without label 0\n",
    "not_zeros_test = label_test != 0\n",
    "img_test = img_test[not_zeros_test]\n",
    "label_test = label_test[not_zeros_test]\n",
    "\n",
    "# how much data will be considered\n",
    "count_train = 10000\n",
    "count_test = 3000\n",
    "n_operands = 2\n",
    "\n",
    "# operation\n",
    "op = lambda args: args[0]%args[1]\n",
    "\n",
    "# train data\n",
    "img_per_operand_train = [img_train[i*count_train:i*count_train+count_train] for i in range(n_operands)]\n",
    "label_per_operand_train = [label_train[i*count_train:i*count_train+count_train] for i in range(n_operands)]\n",
    "label_result_train = np.apply_along_axis(op,0,label_per_operand_train)\n",
    "\n",
    "# test data\n",
    "img_per_operand_test = [img_test[i*count_test:i*count_test+count_test] for i in range(n_operands)]\n",
    "label_per_operand_test = [label_test[i*count_test:i*count_test+count_test] for i in range(n_operands)]\n",
    "label_result_test = np.apply_along_axis(op,0,label_per_operand_test)"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating tf datasets of specific buffer and batch size"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T13:13:45.060453Z",
     "start_time": "2025-06-02T13:13:44.976842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "buffer_size = 3000\n",
    "batch_size  = 16\n",
    "\n",
    "# training set\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(\n",
    "              ((img_per_operand_train[0],\n",
    "                img_per_operand_train[1]),\n",
    "               label_result_train)\n",
    "           )\\\n",
    "           .shuffle(buffer_size)\\\n",
    "           .batch(batch_size)\\\n",
    "           .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# test set\n",
    "ds_test  = tf.data.Dataset.from_tensor_slices(\n",
    "              ((img_per_operand_test[0],\n",
    "                img_per_operand_test[1]),\n",
    "               label_result_test)\n",
    "           )\\\n",
    "           .batch(batch_size)\\\n",
    "           .prefetch(tf.data.AUTOTUNE)"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Neural Network"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T13:14:34.670451Z",
     "start_time": "2025-06-02T13:13:45.060453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instantiate model\n",
    "n_classes = 9\n",
    "model = baselines.MultiDigits(n_classes=n_classes, hidden_dense_sizes=(84,))\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model.fit(ds_train, epochs=10)\n",
    "test_loss, test_accuracy = model.evaluate(ds_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
   ],
   "execution_count": 26,
   "outputs": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12eaedf9b9a64329743e8900a3192e3d75dbaaa78715534825922e4a4f7d9137"
  },
  "kernelspec": {
   "display_name": "Python 3.12 (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
