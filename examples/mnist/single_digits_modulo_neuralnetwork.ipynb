{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Changes: core->_SoftmaxTfModel -> SoftmaxTfModel\n",
    " metrics.reset_states() -> metrics.reset_state()\n",
    " remove 0 from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:59:22.714819Z",
     "start_time": "2025-05-28T17:59:22.708965Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "import baselines, data, commons\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset preprocessing\n",
    "## Importing dataset"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:59:23.297493Z",
     "start_time": "2025-05-28T17:59:22.755584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(img_train, label_train), (img_test, label_test) = mnist.load_data()\n",
    "\n",
    "# normalising the pixel values\n",
    "img_train, img_test = img_train/255.0, img_test/255.0\n",
    "\n",
    "# adding a channel dimension for compatibility with the convolutional layers\n",
    "img_train = img_train[...,tf.newaxis]\n",
    "img_test = img_test[...,tf.newaxis]"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Removing images with the 0 digit"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:59:23.581612Z",
     "start_time": "2025-05-28T17:59:23.297493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train data without label 0\n",
    "not_zeros_train = label_train != 0\n",
    "img_train = img_train[not_zeros_train]\n",
    "label_train = label_train[not_zeros_train]\n",
    "\n",
    "#test data without label 0\n",
    "not_zeros_test = label_test != 0\n",
    "img_test = img_test[not_zeros_test]\n",
    "label_test = label_test[not_zeros_test]\n",
    "\n",
    "# how much data will be considered\n",
    "count_train = 10000\n",
    "count_test = 3000\n",
    "n_operands = 2\n",
    "\n",
    "# operation\n",
    "op = lambda args: args[0]%args[1]\n",
    "\n",
    "# train data\n",
    "img_per_operand_train = [img_train[i*count_train:i*count_train+count_train] for i in range(n_operands)]\n",
    "label_per_operand_train = [label_train[i*count_train:i*count_train+count_train] for i in range(n_operands)]\n",
    "label_result_train = np.apply_along_axis(op,0,label_per_operand_train)\n",
    "\n",
    "# test data\n",
    "img_per_operand_test = [img_test[i*count_test:i*count_test+count_test] for i in range(n_operands)]\n",
    "label_per_operand_test = [label_test[i*count_test:i*count_test+count_test] for i in range(n_operands)]\n",
    "label_result_test = np.apply_along_axis(op,0,label_per_operand_test)"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating tf datasets of specific buffer and batch size"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:59:23.657572Z",
     "start_time": "2025-05-28T17:59:23.581612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "buffer_size = 3000\n",
    "batch_size  = 16\n",
    "\n",
    "# training set\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(\n",
    "              ((img_per_operand_train[0],\n",
    "                img_per_operand_train[1]),\n",
    "               label_result_train)\n",
    "           )\\\n",
    "           .shuffle(buffer_size)\\\n",
    "           .batch(batch_size)\\\n",
    "           .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# test set\n",
    "ds_test  = tf.data.Dataset.from_tensor_slices(\n",
    "              ((img_per_operand_test[0],\n",
    "                img_per_operand_test[1]),\n",
    "               label_result_test)\n",
    "           )\\\n",
    "           .batch(batch_size)\\\n",
    "           .prefetch(tf.data.AUTOTUNE)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Neural Network"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:01:34.696371Z",
     "start_time": "2025-05-28T17:59:23.659583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_base_cnn():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, 3, activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.25)\n",
    "    ], name=\"digit_cnn\")\n",
    "\n",
    "base_cnn = make_base_cnn()\n",
    "\n",
    "inp1 = tf.keras.layers.Input(shape=(28, 28, 1), name=\"x\")\n",
    "inp2 = tf.keras.layers.Input(shape=(28, 28, 1), name=\"y\")\n",
    "\n",
    "feat1 = base_cnn(inp1)\n",
    "feat2 = base_cnn(inp2)\n",
    "\n",
    "concat = tf.keras.layers.Concatenate()([feat1, feat2])\n",
    "out    = tf.keras.layers.Dense(9, activation=\"softmax\")(concat)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inp1, inp2], outputs=out)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=ds_test,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(ds_test, verbose=0)\n",
    "print(f\"\\nModulo-CNN test accuracy: {test_acc:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 - 7s - 10ms/step - accuracy: 0.6197 - loss: 1.0071 - val_accuracy: 0.7130 - val_loss: 0.7097\n",
      "Epoch 2/20\n",
      "625/625 - 6s - 9ms/step - accuracy: 0.7328 - loss: 0.6679 - val_accuracy: 0.7513 - val_loss: 0.6095\n",
      "Epoch 3/20\n",
      "625/625 - 6s - 10ms/step - accuracy: 0.7693 - loss: 0.5833 - val_accuracy: 0.7753 - val_loss: 0.5676\n",
      "Epoch 4/20\n",
      "625/625 - 6s - 10ms/step - accuracy: 0.7876 - loss: 0.5333 - val_accuracy: 0.7860 - val_loss: 0.5344\n",
      "Epoch 5/20\n",
      "625/625 - 6s - 10ms/step - accuracy: 0.7958 - loss: 0.5028 - val_accuracy: 0.7843 - val_loss: 0.5251\n",
      "Epoch 6/20\n",
      "625/625 - 6s - 10ms/step - accuracy: 0.8061 - loss: 0.4688 - val_accuracy: 0.7920 - val_loss: 0.5173\n",
      "Epoch 7/20\n",
      "625/625 - 8s - 12ms/step - accuracy: 0.8111 - loss: 0.4481 - val_accuracy: 0.7930 - val_loss: 0.5382\n",
      "Epoch 8/20\n",
      "625/625 - 9s - 15ms/step - accuracy: 0.8242 - loss: 0.4267 - val_accuracy: 0.7903 - val_loss: 0.5349\n",
      "Epoch 9/20\n",
      "625/625 - 6s - 10ms/step - accuracy: 0.8361 - loss: 0.4080 - val_accuracy: 0.7840 - val_loss: 0.5428\n",
      "Epoch 10/20\n",
      "625/625 - 6s - 10ms/step - accuracy: 0.8449 - loss: 0.3838 - val_accuracy: 0.7870 - val_loss: 0.5667\n",
      "Epoch 11/20\n",
      "625/625 - 6s - 10ms/step - accuracy: 0.8543 - loss: 0.3661 - val_accuracy: 0.7907 - val_loss: 0.5932\n",
      "Epoch 12/20\n",
      "625/625 - 6s - 10ms/step - accuracy: 0.8624 - loss: 0.3452 - val_accuracy: 0.7820 - val_loss: 0.5894\n",
      "Epoch 13/20\n",
      "625/625 - 6s - 10ms/step - accuracy: 0.8709 - loss: 0.3265 - val_accuracy: 0.7840 - val_loss: 0.6051\n",
      "Epoch 14/20\n",
      "625/625 - 7s - 11ms/step - accuracy: 0.8849 - loss: 0.3018 - val_accuracy: 0.7780 - val_loss: 0.6333\n",
      "Epoch 15/20\n",
      "625/625 - 7s - 11ms/step - accuracy: 0.8874 - loss: 0.2918 - val_accuracy: 0.7840 - val_loss: 0.6264\n",
      "Epoch 16/20\n",
      "625/625 - 6s - 10ms/step - accuracy: 0.8972 - loss: 0.2649 - val_accuracy: 0.7707 - val_loss: 0.6973\n",
      "Epoch 17/20\n",
      "625/625 - 6s - 10ms/step - accuracy: 0.9010 - loss: 0.2562 - val_accuracy: 0.7697 - val_loss: 0.7398\n",
      "Epoch 18/20\n",
      "625/625 - 6s - 10ms/step - accuracy: 0.9091 - loss: 0.2363 - val_accuracy: 0.7777 - val_loss: 0.7282\n",
      "Epoch 19/20\n",
      "625/625 - 6s - 10ms/step - accuracy: 0.9183 - loss: 0.2269 - val_accuracy: 0.7767 - val_loss: 0.8019\n",
      "Epoch 20/20\n",
      "625/625 - 6s - 9ms/step - accuracy: 0.9205 - loss: 0.2087 - val_accuracy: 0.7723 - val_loss: 0.7954\n",
      "\n",
      "Modulo-CNN test accuracy: 0.7723\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12eaedf9b9a64329743e8900a3192e3d75dbaaa78715534825922e4a4f7d9137"
  },
  "kernelspec": {
   "display_name": "Python 3.12 (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
