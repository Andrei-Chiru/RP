{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T20:27:22.923048Z",
     "start_time": "2025-05-12T20:27:22.913083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split\n",
    "import commons\n",
    "from collections import defaultdict"
   ],
   "id": "3b84c8d9c5b12e74",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T20:24:46.967573Z",
     "start_time": "2025-05-12T20:24:40.295509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "poker = fetch_ucirepo(id=158)\n",
    "X, y = poker.data.features, poker.data.targets\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "X_np = X_train.to_numpy()\n",
    "y_np = y_train.to_numpy()\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((X_np, y_np))\n",
    "X_np = X_val.to_numpy()\n",
    "y_np = y_val.to_numpy()\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((X_np, y_np))\n",
    "X_np = X_test.to_numpy()\n",
    "y_np = y_test.to_numpy()\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((X_np, y_np))"
   ],
   "id": "77af0307d2ee4df9",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T20:24:46.972310Z",
     "start_time": "2025-05-12T20:24:46.967573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, n_hidden=32, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(n_hidden, activation=\"relu\")\n",
    "        self.dense2 = tf.keras.layers.Dense(n_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        hand,label = inputs\n",
    "        x = self.dense1(hand)\n",
    "        probs = self.dense2(x)\n",
    "        truth = tf.reduce_sum(probs * label, axis=-1, keepdims=True)\n",
    "        return truth"
   ],
   "id": "f8a6cb4cd06b57fb",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T20:24:46.984974Z",
     "start_time": "2025-05-12T20:24:46.972310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Predicates\n",
    "HandType = ltn.Predicate(Model())\n",
    "# Operators\n",
    "Not     = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And     = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or      = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "\n",
    "Forall  = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(p=4), 'forall')  # ∀\n",
    "Exists  = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(),        'exists')   # ∃\n",
    "Equiv   = ltn.Wrapper_Connective(ltn.fuzzy_ops.Equiv(And, Implies))\n"
   ],
   "id": "5bce6e00ea61190e",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T20:24:52.418261Z",
     "start_time": "2025-05-12T20:24:52.395963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def bincount_batch(ranks, length=14): #13 bins 1-13\n",
    "    return tf.map_fn( #apply to every row\n",
    "        #count how many times each value appears in the input\n",
    "        #and cast the output to float 32 to be used by predicates and fuzzy operations\n",
    "        lambda row: tf.cast(tf.math.bincount(row,\n",
    "                                             minlength=length,\n",
    "                                             maxlength=length), tf.float32),\n",
    "        ranks)\n",
    "\n",
    "def same_suit(hand):\n",
    "    suits  = hand[:, 0:10:2]\n",
    "    truth  = tf.reduce_all(suits[:, 1:] == suits[:, :1], axis=1, keepdims=True)\n",
    "    return tf.cast(truth, tf.float32)\n",
    "\n",
    "def two_of_a_kind(hand):\n",
    "    counts   = bincount_batch(hand[:, 1:10:2])            # [b,14]\n",
    "    twos     = tf.reduce_sum(tf.cast(counts == 2, tf.float32), axis=1, keepdims=True)\n",
    "    threes   = tf.reduce_sum(tf.cast(counts == 3, tf.float32), axis=1, keepdims=True)\n",
    "    fours    = tf.reduce_sum(tf.cast(counts == 4, tf.float32), axis=1, keepdims=True)\n",
    "    truth    = tf.cast((twos == 1) & (threes == 0) & (fours == 0), tf.float32)\n",
    "    return truth\n",
    "\n",
    "def two_of_two_kinds(hand):\n",
    "    counts = bincount_batch(hand[:, 1:10:2])\n",
    "    pairs  = tf.reduce_sum(tf.cast(counts == 2, tf.float32), axis=1, keepdims=True)\n",
    "    truth  = tf.cast(pairs == 2, tf.float32)\n",
    "    return truth\n",
    "\n",
    "def three_of_a_kind(hand):\n",
    "    counts  = bincount_batch(hand[:, 1:10:2])\n",
    "    threes  = tf.reduce_sum(tf.cast(counts == 3, tf.float32), axis=1, keepdims=True)\n",
    "    twos    = tf.reduce_sum(tf.cast(counts == 2, tf.float32), axis=1, keepdims=True)\n",
    "    truth   = tf.cast((threes == 1) & (twos == 0), tf.float32)\n",
    "    return truth\n",
    "\n",
    "def four_of_a_kind(hand):\n",
    "    counts = bincount_batch(hand[:, 1:10:2])\n",
    "    quads  = tf.reduce_sum(tf.cast(counts == 4, tf.float32), axis=1, keepdims=True)\n",
    "    return tf.cast(quads == 1, tf.float32)\n",
    "\n",
    "def two_of_a_kind_three_of_a_kind(hand):       # full house\n",
    "    counts  = bincount_batch(hand[:, 1:10:2])\n",
    "    threes  = tf.reduce_sum(tf.cast(counts == 3, tf.float32), axis=1, keepdims=True)\n",
    "    twos    = tf.reduce_sum(tf.cast(counts == 2, tf.float32), axis=1, keepdims=True)\n",
    "    return tf.cast((threes == 1) & (twos == 1), tf.float32)\n",
    "\n",
    "def five_sequence(hand):                       # straight\n",
    "    ranks, _  = tf.sort(hand[:, 1:10:2], axis=1)\n",
    "    diffs     = ranks[:, 1:] - ranks[:, :-1]\n",
    "    truth     = tf.reduce_all(diffs == 1, axis=1, keepdims=True)\n",
    "    return tf.cast(truth, tf.float32)\n",
    "\n",
    "def straight_flush(hand):\n",
    "    return tf.cast((same_suit(hand) == 1.0) & (five_sequence(hand) == 1.0), tf.float32)\n",
    "\n",
    "def royal_flush(hand):\n",
    "    royal   = tf.constant([1,10,11,12,13], dtype=tf.int32)\n",
    "    ranks   = tf.sort(hand[:, 1:10:2], axis=1)[0]\n",
    "    match   = tf.reduce_all(tf.equal(ranks, royal), axis=1, keepdims=True)\n",
    "    return tf.cast((same_suit(hand) == 1.0) & match, tf.float32)\n",
    "\n",
    "def nothing_hand(hand):\n",
    "    truth = ~(\n",
    "        (two_of_a_kind(hand)               == 1.0) |\n",
    "        (two_of_two_kinds(hand)            == 1.0) |\n",
    "        (three_of_a_kind(hand)             == 1.0) |\n",
    "        (five_sequence(hand)               == 1.0) |\n",
    "        (same_suit(hand)                   == 1.0) |\n",
    "        (two_of_a_kind_three_of_a_kind(hand) == 1.0) |\n",
    "        (four_of_a_kind(hand)              == 1.0) |\n",
    "        (straight_flush(hand)              == 1.0) |\n",
    "        (royal_flush(hand)                 == 1.0)\n",
    "    )\n",
    "    return tf.cast(truth, tf.float32)\n",
    "\n",
    "equals = ltn.Predicate.Lambda(\n",
    "    lambda x, y: tf.cast(\n",
    "        tf.reduce_all(tf.equal(x, y), axis=-1, keepdims=True),\n",
    "        tf.float32)\n",
    ")\n",
    "NothingRule       = ltn.Predicate.Lambda(nothing_hand)\n",
    "OnePairRule       = ltn.Predicate.Lambda(two_of_a_kind)\n",
    "TwoPairRule       = ltn.Predicate.Lambda(two_of_two_kinds)\n",
    "ThreeOfAKindRule  = ltn.Predicate.Lambda(three_of_a_kind)\n",
    "StraightRule      = ltn.Predicate.Lambda(five_sequence)\n",
    "FlushRule         = ltn.Predicate.Lambda(same_suit)\n",
    "FullHouseRule     = ltn.Predicate.Lambda(two_of_a_kind_three_of_a_kind)\n",
    "FourOfAKindRule   = ltn.Predicate.Lambda(four_of_a_kind)\n",
    "StraightFlushRule = ltn.Predicate.Lambda(straight_flush)\n",
    "RoyalFlushRule    = ltn.Predicate.Lambda(royal_flush)"
   ],
   "id": "baefac771e14e36e",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T20:25:42.066125Z",
     "start_time": "2025-05-12T20:25:41.555043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Nothing, OnePair, TwoPairs, ThreeOfAKind,Straight,Flush,FullHouse,FourOfAKind, StraightFlush, RoyalFlush = tf.eye(10)\n",
    "@tf.function\n",
    "def axioms(hand,label):\n",
    "    # Variables\n",
    "    hand_variable = ltn.Variable(\"hand_variable\", hand)\n",
    "    label_variable = ltn.Variable(\"label_variable\", label)\n",
    "    #this creates a tensor for every class\n",
    "    \n",
    "    \n",
    "    label_domain = tf.eye(10)\n",
    "    l1 = ltn.Variable(\"l1\",label_domain)\n",
    "    l2 = ltn.Variable(\"l2\",label_domain)\n",
    "    supervised_rule = Forall(ltn.diag(hand_variable,label_variable), HandType([hand_variable, label_variable]), p=2)\n",
    "    \n",
    "    # x_rule(hand) -> hand has label x\n",
    "    rule_axioms = [\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   NothingRule(hand_variable),\n",
    "                   HandType([hand_variable,Nothing])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   OnePairRule(hand_variable),\n",
    "                   HandType([hand_variable,OnePair])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   TwoPairRule(hand_variable),\n",
    "                   HandType([hand_variable,TwoPairs])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   ThreeOfAKindRule(hand_variable),\n",
    "                   HandType([hand_variable,ThreeOfAKind])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   StraightRule(hand_variable),\n",
    "                   HandType([hand_variable,Straight])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   FlushRule(hand_variable),\n",
    "                   HandType([hand_variable,Flush])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   FullHouseRule(hand_variable),\n",
    "                   HandType([hand_variable,FullHouse])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   FourOfAKindRule(hand_variable),\n",
    "                   HandType([hand_variable,FourOfAKind])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   StraightFlushRule(hand_variable),\n",
    "                   HandType([hand_variable,StraightFlush])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   RoyalFlushRule(hand_variable),\n",
    "                   HandType([hand_variable,RoyalFlush])), p=2),\n",
    "    ]\n",
    "    #a hand cannot have two types at once\n",
    "    exclusivity_rule = Implies(~equals(l1, l2),\n",
    "            ~(And(HandType([hand_variable, l1]),\n",
    "                      HandType([hand_variable, l2]))))\n",
    "    \n",
    "    all_axioms = ltn.LTNCollection([supervised_rule, *rule_axioms, exclusivity_rule])\n",
    "\n",
    "    return all_axioms.tensor\n",
    "\n",
    "x1, y1 = next(ds_train.as_numpy_iterator())\n",
    "axioms(x1,y1)"
   ],
   "id": "411e7c78b40fb274",
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\1119039408.py\", line 16, in axioms  *\n        rule_axioms = [\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 189, in __call__  *\n        expr = super().__call__(inputs, *args, **kwargs)\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 155, in __call__  *\n        t_outputs = self.model(flat_inputs[0].tensor, *args, **kwargs)\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 306, in call\n        return self.lambda_layer(inputs)\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\3742157694.py\", line 67, in nothing_hand\n        (five_sequence(hand)               == 1.0) |\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\3742157694.py\", line 48, in five_sequence\n        ranks, _  = tf.sort(hand[:, 1:10:2], axis=1)\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling Lambda.call().\n    \n    \u001B[1mIterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\u001B[0m\n    \n    Arguments received by Lambda.call():\n      • inputs=tf.Tensor(shape=(10, 1), dtype=float32)\n      • mask=None\n      • training=None\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOperatorNotAllowedInGraphError\u001B[39m            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[41]\u001B[39m\u001B[32m, line 69\u001B[39m\n\u001B[32m     65\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m all_axioms.tensor\n\u001B[32m     67\u001B[39m x1, y1 = \u001B[38;5;28mnext\u001B[39m(ds_train.as_numpy_iterator())\n\u001B[32m---> \u001B[39m\u001B[32m69\u001B[39m \u001B[43maxioms\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx1\u001B[49m\u001B[43m,\u001B[49m\u001B[43my1\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RP\\.venv312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    152\u001B[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m--> \u001B[39m\u001B[32m153\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    154\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    155\u001B[39m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RP\\.venv312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:52\u001B[39m, in \u001B[36mpy_func_from_autograph.<locals>.autograph_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     50\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[32m     51\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[33m\"\u001B[39m\u001B[33mag_error_metadata\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e.ag_error_metadata.to_exception(e)\n\u001B[32m     53\u001B[39m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[31mOperatorNotAllowedInGraphError\u001B[39m: in user code:\n\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\1119039408.py\", line 16, in axioms  *\n        rule_axioms = [\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 189, in __call__  *\n        expr = super().__call__(inputs, *args, **kwargs)\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 155, in __call__  *\n        t_outputs = self.model(flat_inputs[0].tensor, *args, **kwargs)\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 306, in call\n        return self.lambda_layer(inputs)\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\3742157694.py\", line 67, in nothing_hand\n        (five_sequence(hand)               == 1.0) |\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\3742157694.py\", line 48, in five_sequence\n        ranks, _  = tf.sort(hand[:, 1:10:2], axis=1)\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling Lambda.call().\n    \n    \u001B[1mIterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\u001B[0m\n    \n    Arguments received by Lambda.call():\n      • inputs=tf.Tensor(shape=(10, 1), dtype=float32)\n      • mask=None\n      • training=None\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T20:26:19.231747Z",
     "start_time": "2025-05-12T20:26:19.070038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Nothing, OnePair, TwoPairs, ThreeOfAKind,Straight,Flush,FullHouse,FourOfAKind, StraightFlush, RoyalFlush = tf.eye(10)\n",
    "@tf.function\n",
    "def axioms(hand,label,p_schedule):\n",
    "    hand_variable = ltn.Variable(\"hand_variable\", hand)\n",
    "    label_variable = ltn.Variable(\"label_variable\", label)\n",
    "    #this creates a tensor for every class\n",
    "    \n",
    "    \n",
    "    label_domain = tf.eye(10)\n",
    "    l1 = ltn.Variable(\"l1\",label_domain)\n",
    "    l2 = ltn.Variable(\"l2\",label_domain)\n",
    "    supervised_rule = Forall(ltn.diag(hand_variable,label_variable), HandType([hand_variable, label_variable]), p=2)\n",
    "    \n",
    "    # x_rule(hand) -> hand has label x\n",
    "    rule_axioms = [\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   NothingRule(hand_variable),\n",
    "                   HandType([hand_variable,Nothing])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   OnePairRule(hand_variable),\n",
    "                   HandType([hand_variable,OnePair])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   TwoPairRule(hand_variable),\n",
    "                   HandType([hand_variable,TwoPairs])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   ThreeOfAKindRule(hand_variable),\n",
    "                   HandType([hand_variable,ThreeOfAKind])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   StraightRule(hand_variable),\n",
    "                   HandType([hand_variable,Straight])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   FlushRule(hand_variable),\n",
    "                   HandType([hand_variable,Flush])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   FullHouseRule(hand_variable),\n",
    "                   HandType([hand_variable,FullHouse])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   FourOfAKindRule(hand_variable),\n",
    "                   HandType([hand_variable,FourOfAKind])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   StraightFlushRule(hand_variable),\n",
    "                   HandType([hand_variable,StraightFlush])), p=2),\n",
    "        Forall(hand_variable,\n",
    "               Implies(\n",
    "                   RoyalFlushRule(hand_variable),\n",
    "                   HandType([hand_variable,RoyalFlush])), p=2),\n",
    "    ]\n",
    "    #a hand cannot have two types at once\n",
    "    exclusivity_rule = Implies(~equals(l1, l2),\n",
    "            ~(And(HandType([hand_variable, l1]),\n",
    "                      HandType([hand_variable, l2]))))\n",
    "    \n",
    "    all_axioms = ltn.LTNCollection([supervised_rule, *rule_axioms, exclusivity_rule])\n",
    "\n",
    "    return all_axioms.tensor\n",
    "\n",
    "x1, y1 = next(ds_train.as_numpy_iterator())\n",
    "axioms(x1,y1, tf.constant(2.))"
   ],
   "id": "3f488f272045bbf7",
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\186501409.py\", line 15, in axioms  *\n        rule_axioms = [\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 189, in __call__  *\n        expr = super().__call__(inputs, *args, **kwargs)\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 155, in __call__  *\n        t_outputs = self.model(flat_inputs[0].tensor, *args, **kwargs)\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 306, in call\n        return self.lambda_layer(inputs)\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\3742157694.py\", line 67, in nothing_hand\n        (five_sequence(hand)               == 1.0) |\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\3742157694.py\", line 48, in five_sequence\n        ranks, _  = tf.sort(hand[:, 1:10:2], axis=1)\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling Lambda.call().\n    \n    \u001B[1mIterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\u001B[0m\n    \n    Arguments received by Lambda.call():\n      • inputs=tf.Tensor(shape=(10, 1), dtype=float32)\n      • mask=None\n      • training=None\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOperatorNotAllowedInGraphError\u001B[39m            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[43]\u001B[39m\u001B[32m, line 67\u001B[39m\n\u001B[32m     64\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m all_axioms.tensor\n\u001B[32m     66\u001B[39m x1, y1 = \u001B[38;5;28mnext\u001B[39m(ds_train.as_numpy_iterator())\n\u001B[32m---> \u001B[39m\u001B[32m67\u001B[39m \u001B[43maxioms\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx1\u001B[49m\u001B[43m,\u001B[49m\u001B[43my1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconstant\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m2.\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RP\\.venv312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    152\u001B[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m--> \u001B[39m\u001B[32m153\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    154\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    155\u001B[39m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RP\\.venv312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:52\u001B[39m, in \u001B[36mpy_func_from_autograph.<locals>.autograph_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     50\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[32m     51\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[33m\"\u001B[39m\u001B[33mag_error_metadata\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e.ag_error_metadata.to_exception(e)\n\u001B[32m     53\u001B[39m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[31mOperatorNotAllowedInGraphError\u001B[39m: in user code:\n\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\186501409.py\", line 15, in axioms  *\n        rule_axioms = [\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 189, in __call__  *\n        expr = super().__call__(inputs, *args, **kwargs)\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 155, in __call__  *\n        t_outputs = self.model(flat_inputs[0].tensor, *args, **kwargs)\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 306, in call\n        return self.lambda_layer(inputs)\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\3742157694.py\", line 67, in nothing_hand\n        (five_sequence(hand)               == 1.0) |\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\3742157694.py\", line 48, in five_sequence\n        ranks, _  = tf.sort(hand[:, 1:10:2], axis=1)\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling Lambda.call().\n    \n    \u001B[1mIterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\u001B[0m\n    \n    Arguments received by Lambda.call():\n      • inputs=tf.Tensor(shape=(10, 1), dtype=float32)\n      • mask=None\n      • training=None\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T20:26:23.565519Z",
     "start_time": "2025-05-12T20:26:23.557571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "metrics_dict = {\n",
    "    'train_loss': tf.keras.metrics.Mean(name=\"train_loss\"),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_loss': tf.keras.metrics.Mean(name=\"test_loss\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\")    \n",
    "}"
   ],
   "id": "d9ea1887c1bbd4cc",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T20:26:27.063082Z",
     "start_time": "2025-05-12T20:26:27.056016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@tf.function\n",
    "def train_step(hand,label, **parameters):\n",
    "    # loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1.- axioms(hand, label, **parameters)\n",
    "    gradients = tape.gradient(loss, HandType.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, HandType.trainable_variables))\n",
    "    metrics_dict['train_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions = tf.argmax(HandType([hand]),axis=-1)\n",
    "    match = tf.equal(label,tf.cast(predictions,label.dtype))\n",
    "    metrics_dict['train_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))"
   ],
   "id": "f3f3d785323e4f0a",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T20:26:27.457741Z",
     "start_time": "2025-05-12T20:26:27.449903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@tf.function\n",
    "def test_step(hand,label, **parameters):\n",
    "    # loss\n",
    "    loss = 1.- axioms(hand,label, **parameters)\n",
    "    metrics_dict['test_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions = tf.argmax(HandType([hand]),axis=-1)\n",
    "    match = tf.equal(label,tf.cast(predictions,label.dtype))\n",
    "    metrics_dict['train_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))"
   ],
   "id": "e583390a8ce9fe8c",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T20:27:32.323992Z",
     "start_time": "2025-05-12T20:27:32.138668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scheduled_parameters = defaultdict(lambda: {})\n",
    "for epoch in range(0,4):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(1.)}\n",
    "for epoch in range(4,8):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(2.)}\n",
    "for epoch in range(8,12):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(4.)}\n",
    "for epoch in range(12,20):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(6.)}\n",
    "commons.train(\n",
    "    20,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    scheduled_parameters=scheduled_parameters\n",
    ")"
   ],
   "id": "ca03299627e503ec",
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\592393324.py\", line 5, in train_step  *\n        loss = 1.- axioms(hand, label, **parameters)\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\186501409.py\", line 15, in axioms  *\n        rule_axioms = [\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 189, in __call__  *\n        expr = super().__call__(inputs, *args, **kwargs)\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 155, in __call__  *\n        t_outputs = self.model(flat_inputs[0].tensor, *args, **kwargs)\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 306, in call\n        return self.lambda_layer(inputs)\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\3742157694.py\", line 67, in nothing_hand\n        (five_sequence(hand)               == 1.0) |\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\3742157694.py\", line 48, in five_sequence\n        ranks, _  = tf.sort(hand[:, 1:10:2], axis=1)\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling Lambda.call().\n    \n    \u001B[1mIterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\u001B[0m\n    \n    Arguments received by Lambda.call():\n      • inputs=tf.Tensor(shape=(10, 1), dtype=float32)\n      • mask=None\n      • training=None\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOperatorNotAllowedInGraphError\u001B[39m            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[51]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m12\u001B[39m,\u001B[32m20\u001B[39m):\n\u001B[32m      9\u001B[39m     scheduled_parameters[epoch] = {\u001B[33m\"\u001B[39m\u001B[33mp_schedule\u001B[39m\u001B[33m\"\u001B[39m:tf.constant(\u001B[32m6.\u001B[39m)}\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m \u001B[43mcommons\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m    \u001B[49m\u001B[32;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmetrics_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m    \u001B[49m\u001B[43mds_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m    \u001B[49m\u001B[43mds_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtest_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[43m    \u001B[49m\u001B[43mscheduled_parameters\u001B[49m\u001B[43m=\u001B[49m\u001B[43mscheduled_parameters\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RP\\commons.py:43\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m(epochs, metrics_dict, ds_train, ds_test, train_step, test_step, csv_path, scheduled_parameters)\u001B[39m\n\u001B[32m     40\u001B[39m     metrics.reset_state()\n\u001B[32m     42\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m batch_elements \u001B[38;5;129;01min\u001B[39;00m ds_train:\n\u001B[32m---> \u001B[39m\u001B[32m43\u001B[39m     \u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43mbatch_elements\u001B[49m\u001B[43m,\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mscheduled_parameters\u001B[49m\u001B[43m[\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     44\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m batch_elements \u001B[38;5;129;01min\u001B[39;00m ds_test:\n\u001B[32m     45\u001B[39m     test_step(*batch_elements,**scheduled_parameters[epoch])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RP\\.venv312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    152\u001B[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m--> \u001B[39m\u001B[32m153\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    154\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    155\u001B[39m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\RP\\.venv312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:52\u001B[39m, in \u001B[36mpy_func_from_autograph.<locals>.autograph_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     50\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[32m     51\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[33m\"\u001B[39m\u001B[33mag_error_metadata\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e.ag_error_metadata.to_exception(e)\n\u001B[32m     53\u001B[39m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[31mOperatorNotAllowedInGraphError\u001B[39m: in user code:\n\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\592393324.py\", line 5, in train_step  *\n        loss = 1.- axioms(hand, label, **parameters)\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\186501409.py\", line 15, in axioms  *\n        rule_axioms = [\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 189, in __call__  *\n        expr = super().__call__(inputs, *args, **kwargs)\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 155, in __call__  *\n        t_outputs = self.model(flat_inputs[0].tensor, *args, **kwargs)\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\andre\\Desktop\\RP\\.venv312\\Lib\\site-packages\\ltn\\core.py\", line 306, in call\n        return self.lambda_layer(inputs)\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\3742157694.py\", line 67, in nothing_hand\n        (five_sequence(hand)               == 1.0) |\n    File \"C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_20184\\3742157694.py\", line 48, in five_sequence\n        ranks, _  = tf.sort(hand[:, 1:10:2], axis=1)\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling Lambda.call().\n    \n    \u001B[1mIterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\u001B[0m\n    \n    Arguments received by Lambda.call():\n      • inputs=tf.Tensor(shape=(10, 1), dtype=float32)\n      • mask=None\n      • training=None\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "82926ee07d41c4c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (venv312)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
