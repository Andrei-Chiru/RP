{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Addition Problem\n",
    "\n",
    "Consider a task where one needs to learn a classifier $\\mathtt{addition(X,Y,N)}$ where $\\mathtt{X}$ and $\\mathtt{Y}$ are images of digits (the MNIST data set will be used), and $\\mathtt{N}$ is a natural number corres"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "ponding to the sum of these digits. The classifier should return an estimate of the validity of the addition ($0$ is invalid, $1$ is valid). \n",
    "\n",
    "For instance, if $\\mathtt{X}$ is an image of a 0 and $\\mathtt{Y}$ is an image of a 9:\n",
    "- if $\\mathtt{N} = 9$, then the addition is valid; \n",
    "- if $\\mathtt{N} = 4$, then the addition is not valid. \n",
    "\n",
    "A natural approach is to seek to first 1) learn a single digit classifier, then 2) benefit from knowledge readily available about the properties of addition.\n",
    "For instance, suppose that a predicate $\\mathrm{digit}(x,d)$ gives the likelihood of an image $x$ being of digit $d$, one could query with LTN:    \n",
    "$$\n",
    "\\exists d_1,d_2 : d_1+d_2= \\mathtt{N} \\ (\\mathrm{digit}(\\mathtt{X},d_1)\\land \\mathrm{digit}(\\mathtt{Y},d_2))\n",
    "$$\n",
    "and use the satisfaction of this query as the output of $\\mathtt{addition(X,Y,N)}$ .\n",
    "\n",
    "\n",
    "The challenge is the following:\n",
    "- We provide, in the data, pairs of images $\\mathtt{X}$, $\\mathtt{Y}$ and the result of the addition $\\mathtt{N}$ (final label),\n",
    "- We do **not** provide the intermediate labels, the correct digits for $d_1$, $d_2$.\n",
    "\n",
    "Regardless, it is possible to use the equation above as background knowledge to train $\\mathrm{digit}$ with LTN.\n",
    "In contrast, a standard neural network baseline cannot incorporate such intermediate components as nicely."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:22:01.575994Z",
     "start_time": "2025-05-06T08:22:01.569186Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "import baselines, data, commons\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Dataset of images for the digits X and Y, and their label Z s.t. X+Y=Z."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:22:03.255512Z",
     "start_time": "2025-05-06T08:22:02.157872Z"
    }
   },
   "source": [
    "ds_train, ds_test = data.get_mnist_op_dataset(\n",
    "        count_train=3000,\n",
    "        count_test=1000,\n",
    "        buffer_size=3000,\n",
    "        batch_size=16,\n",
    "        n_operands=2,\n",
    "        op=lambda args: args[0]+args[1])\n",
    "\n",
    "# Visualize one example\n",
    "x, y, z = next(ds_train.as_numpy_iterator())\n",
    "plt.subplot(121)\n",
    "plt.imshow(x[0][:,:,0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(y[0][:,:,0])\n",
    "print(\"Result label is %i\" % z[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result label is 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LTN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:22:03.382001Z",
     "start_time": "2025-05-06T08:22:03.365175Z"
    }
   },
   "source": [
    "logits_model = baselines.SingleDigit(inputs_as_a_list=True)\n",
    "\n",
    "# Digit = ltn.Predicate.FromLogits(logits_model, activation_function=\"softmax\")\n",
    "# FromLogits lets you override the scope name\n",
    "Digit = ltn.Predicate.FromLogits(\n",
    "    logits_model,\n",
    "    activation_function=\"softmax\",\n",
    "    name=\"softmaxDigit\"          # ← must begin with [A-Za-z0-9.]\n",
    ")\n",
    "\n",
    "\n",
    "d1 = ltn.Variable(\"digits1\", range(10))\n",
    "d2 = ltn.Variable(\"digits2\", range(10))\n",
    "\n",
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(),semantics=\"exists\")"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the use of `Diag`: when grounding $x$,$y$,$n$ with three sequences of values, the $i$-th examples of each variable are matching. \n",
    "That is, `(images_x[i],images_y[i],labels[i])` is a tuple from our dataset of valid additions.\n",
    "Using the diagonal quantification, LTN aggregates pairs of images and their corresponding result, rather than any combination of images and results. \n",
    "    \n",
    "Notice also the guarded quantification: by quantifying only on the \"intermediate labels\" (not given during training) that could add up to the result label (given during training), we incorporate symbolic information into the system."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:22:09.194607Z",
     "start_time": "2025-05-06T08:22:06.108504Z"
    }
   },
   "source": [
    "# mask\n",
    "add = ltn.Function.Lambda(lambda inputs: inputs[0]+inputs[1])\n",
    "equals = ltn.Predicate.Lambda(lambda inputs: inputs[0] == inputs[1])\n",
    "\n",
    "### Axioms\n",
    "@tf.function\n",
    "def axioms(images_x, images_y, labels_z, p_schedule=tf.constant(2.)):\n",
    "    images_x = ltn.Variable(\"x\", images_x)\n",
    "    images_y = ltn.Variable(\"y\", images_y)\n",
    "    labels_z = ltn.Variable(\"z\", labels_z)\n",
    "    axiom = Forall(\n",
    "            ltn.diag(images_x,images_y,labels_z),\n",
    "            Exists(\n",
    "                (d1,d2),\n",
    "                And(Digit([images_x,d1]),Digit([images_y,d2])),\n",
    "                mask=equals([add([d1,d2]), labels_z]),\n",
    "                p=p_schedule\n",
    "            ),\n",
    "            p=2\n",
    "        )\n",
    "    sat = axiom.tensor\n",
    "    return sat\n",
    "\n",
    "images_x, images_y, labels_z = next(ds_train.as_numpy_iterator())\n",
    "axioms(images_x, images_y, labels_z)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.010746896266937256>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, training steps and metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:22:10.481794Z",
     "start_time": "2025-05-06T08:22:10.432488Z"
    }
   },
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "metrics_dict = {\n",
    "    'train_loss': tf.keras.metrics.Mean(name=\"train_loss\"),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_loss': tf.keras.metrics.Mean(name=\"test_loss\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\")    \n",
    "}\n",
    "\n",
    "@tf.function\n",
    "def train_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    gradients = tape.gradient(loss, logits_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, logits_model.trainable_variables))\n",
    "    metrics_dict['train_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model([images_x]),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model([images_y]),axis=-1)\n",
    "    predictions_z = predictions_x + predictions_y\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['train_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    metrics_dict['test_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model([images_x]),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model([images_y]),axis=-1)\n",
    "    predictions_z = predictions_x + predictions_y\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['test_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:22:11.899185Z",
     "start_time": "2025-05-06T08:22:11.887070Z"
    }
   },
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "scheduled_parameters = defaultdict(lambda: {})\n",
    "for epoch in range(0,4):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(1.)}\n",
    "for epoch in range(4,8):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(2.)}\n",
    "for epoch in range(8,12):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(4.)}\n",
    "for epoch in range(12,20):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(6.)}"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T08:23:09.211547Z",
     "start_time": "2025-05-06T08:22:12.943829Z"
    }
   },
   "source": [
    "commons.train(\n",
    "    20,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    scheduled_parameters=scheduled_parameters\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 0.9208, train_accuracy: 0.4794, test_loss: 0.8899, test_accuracy: 0.5813\n",
      "Epoch 1, train_loss: 0.8647, train_accuracy: 0.7856, test_loss: 0.8571, test_accuracy: 0.7867\n",
      "Epoch 2, train_loss: 0.8474, train_accuracy: 0.8823, test_loss: 0.8460, test_accuracy: 0.8442\n",
      "Epoch 3, train_loss: 0.8393, train_accuracy: 0.9169, test_loss: 0.8413, test_accuracy: 0.8720\n",
      "Epoch 4, train_loss: 0.6433, train_accuracy: 0.9262, test_loss: 0.6533, test_accuracy: 0.8770\n",
      "Epoch 5, train_loss: 0.6288, train_accuracy: 0.9458, test_loss: 0.6498, test_accuracy: 0.8800\n",
      "Epoch 6, train_loss: 0.6235, train_accuracy: 0.9538, test_loss: 0.6474, test_accuracy: 0.8819\n",
      "Epoch 7, train_loss: 0.6213, train_accuracy: 0.9578, test_loss: 0.6446, test_accuracy: 0.8879\n",
      "Epoch 8, train_loss: 0.4261, train_accuracy: 0.9561, test_loss: 0.4622, test_accuracy: 0.9018\n",
      "Epoch 9, train_loss: 0.4206, train_accuracy: 0.9598, test_loss: 0.4498, test_accuracy: 0.9107\n",
      "Epoch 10, train_loss: 0.4064, train_accuracy: 0.9681, test_loss: 0.4478, test_accuracy: 0.9167\n",
      "Epoch 11, train_loss: 0.4009, train_accuracy: 0.9727, test_loss: 0.4374, test_accuracy: 0.9246\n",
      "Epoch 12, train_loss: 0.3137, train_accuracy: 0.9721, test_loss: 0.3827, test_accuracy: 0.9077\n",
      "Epoch 13, train_loss: 0.3308, train_accuracy: 0.9608, test_loss: 0.3804, test_accuracy: 0.9087\n",
      "Epoch 14, train_loss: 0.3177, train_accuracy: 0.9711, test_loss: 0.3851, test_accuracy: 0.9008\n",
      "Epoch 15, train_loss: 0.3103, train_accuracy: 0.9727, test_loss: 0.3550, test_accuracy: 0.9306\n",
      "Epoch 16, train_loss: 0.3019, train_accuracy: 0.9771, test_loss: 0.3735, test_accuracy: 0.9107\n",
      "Epoch 17, train_loss: 0.3084, train_accuracy: 0.9727, test_loss: 0.3705, test_accuracy: 0.9147\n",
      "Epoch 18, train_loss: 0.3116, train_accuracy: 0.9727, test_loss: 0.3684, test_accuracy: 0.9157\n",
      "Epoch 19, train_loss: 0.3039, train_accuracy: 0.9767, test_loss: 0.3649, test_accuracy: 0.9216\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12eaedf9b9a64329743e8900a3192e3d75dbaaa78715534825922e4a4f7d9137"
  },
  "kernelspec": {
   "display_name": "Python environment",
   "language": "python",
   "name": "environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
