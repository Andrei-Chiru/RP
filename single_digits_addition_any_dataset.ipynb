{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # MNIST Digit Addition Problem\n",
    "\n",
    "Consider a task where one needs to learn a classifier $\\mathtt{addition(X,Y,N)}$ where $\\mathtt{X}$ and $\\mathtt{Y}$ are images of digits (the MNIST data set will be used), and $\\mathtt{N}$ is a natural number corres"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "ponding to the sum of these digits. The classifier should return an estimate of the validity of the addition ($0$ is invalid, $1$ is valid). \n",
    "\n",
    "For instance, if $\\mathtt{X}$ is an image of a 0 and $\\mathtt{Y}$ is an image of a 9:\n",
    "- if $\\mathtt{N} = 9$, then the addition is valid; \n",
    "- if $\\mathtt{N} = 4$, then the addition is not valid. \n",
    "\n",
    "A natural approach is to seek to first 1) learn a single digit classifier, then 2) benefit from knowledge readily available about the properties of addition.\n",
    "For instance, suppose that a predicate $\\mathrm{digit}(x,d)$ gives the likelihood of an image $x$ being of digit $d$, one could query with LTN:    \n",
    "$$\n",
    "\\exists d_1,d_2 : d_1+d_2= \\mathtt{N} \\ (\\mathrm{digit}(\\mathtt{X},d_1)\\land \\mathrm{digit}(\\mathtt{Y},d_2))\n",
    "$$\n",
    "and use the satisfaction of this query as the output of $\\mathtt{addition(X,Y,N)}$ .\n",
    "\n",
    "\n",
    "The challenge is the following:\n",
    "- We provide, in the data, pairs of images $\\mathtt{X}$, $\\mathtt{Y}$ and the result of the addition $\\mathtt{N}$ (final label),\n",
    "- We do **not** provide the intermediate labels, the correct digits for $d_1$, $d_2$.\n",
    "\n",
    "Regardless, it is possible to use the equation above as background knowledge to train $\\mathrm{digit}$ with LTN.\n",
    "In contrast, a standard neural network baseline cannot incorporate such intermediate components as nicely."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T12:07:53.657749Z",
     "start_time": "2025-05-06T12:07:46.020057Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "import baselines, data, commons\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Dataset of images for the digits X and Y, and their label Z s.t. X+Y=Z."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T12:07:59.735905Z",
     "start_time": "2025-05-06T12:07:53.657749Z"
    }
   },
   "source": [
    "ds_train, ds_test = data.get_op_dataset(\n",
    "        data_loader_fn = data.get_emnist_digits_as_numpy,\n",
    "        count_train    = 3000,\n",
    "        count_test     = 1000,\n",
    "        buffer_size    = 3000,\n",
    "        batch_size     = 16,\n",
    "        n_operands     = 2,\n",
    "        op             = lambda args: args[0] + args[1]   # unchanged\n",
    ")\n",
    "\n",
    "# Visualize one example\n",
    "x, y, z = next(ds_train.as_numpy_iterator())\n",
    "plt.subplot(121)\n",
    "plt.imshow(x[0][:,:,0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(y[0][:,:,0])\n",
    "print(\"Result label is %i\" % z[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\andre\\Desktop\\RP\\environment\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1079: The name tf.data.get_output_shapes is deprecated. Please use tf.compat.v1.data.get_output_shapes instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\andre\\Desktop\\RP\\environment\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1079: The name tf.data.get_output_shapes is deprecated. Please use tf.compat.v1.data.get_output_shapes instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result label is 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAEOCAYAAAApP3VyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHa9JREFUeJzt3Q18VPWZ6PFnEpIhQBIMkIRIQgMoqAjsIm9iXSyUiF2WKFWxXhdcqxYJt8DtYtOrWF92U1ErpVC4dz8WdMubtAUWLtIiL6HUBEqQZbGaCzRCEAKCJoEgIcmc/ZzTJiUSnpNkJv/My+/7+RzHmefMOf+cZB6e+c85z3gsy7IEAADAkChTOwIAALBRfAAAAKMoPgAAgFEUHwAAwCiKDwAAYBTFBwAAMIriAwAAGEXxAQAAjKL4AAAARnWQIOPz+eTkyZMSHx8vHo+nvYcDRCS78fH58+clLS1NoqJC4z0KuQMIobxhtZFFixZZvXv3trxerzV8+HBrz549zXpeaWmp3e6dhYUlCBb79WhSa/OGjdzBwiIhkzfaZOZjzZo1MmfOHFm6dKmMGDFCFixYIFlZWVJcXCzJycnqc+13LbY75B7pIDFtMTwALmqlRnbL5obXown+5A0buQMInbzhsSuQQA/AThzDhg2TRYsWNUyHpqeny8yZM+X73/+++tzKykpJTEyUMTJJOnhIIEB7qLVqZKdskIqKCklISDCyT3/yho3cAYRO3gj4h7mXL1+WoqIiGTdu3F93EhXl3C8oKLhq/erqaidpXLkAiCwtzRs2cgcQugJefJw9e1bq6uokJSWl0eP2/bKysqvWz8vLc96t1C/2Ox0AkaWlecNG7gBCV7ufxp6bm+tM0dQvpaWl7T0kACGA3AGEroCfcNq9e3eJjo6W06dPN3rcvp+amnrV+l6v11kARK6W5g0buQMIXQEvPmJjY2Xo0KGybds2yc7ObjhxzL6fk5MT6N0BCAPkDQSL8n8cpcbPDtGv0eh+QO8x0/Wtps9hijRtcqmtfbnc1KlT5bbbbpPhw4c7l8xVVVXJo48+2ha7AxAGyBtA5GiT4uPBBx+UTz/9VObNm+ecLDZkyBDZsmXLVSeTAUA98gYQOdqsvbo9Vcp0KYCWIG8AkaHdr3YBAACRheIDAAAYRfEBAACMovgAAADhccIpAAChZuzs36vxF5MPqPEz37yoxr+d/5DrGGqPhX+3XmY+AACAURQfAADAKIoPAABgFMUHAAAwiuIDAAAYRfEBAACMovgAAABG0ecDAIC/8EbV+vX85OhOarzktUTXbWRMOaXGrVr/xhgMmPkAAABGUXwAAACjKD4AAIBRFB8AAMAoig8AAGAUxQcAADCK4gMAABhFnw8AQMSIvqW/Gv9B95Vq/Cef36DGV5TcpsYLRv6buHnw1m/rK7z/gYQ6Zj4AAIBRFB8AAMAoig8AAGAUxQcAADCK4gMAABhF8QEAAIyi+AAAAEbR5yNIeWJi23T7Vs3lNt0+AAQj6/hJNV5t1ajx9Z8MVuMp086q8bP769R4pAj4zMcPf/hD8Xg8jZYBAwYEejcAwgh5A4gsbTLzccstt8i777771510YIIFgI68AUSONnl120kjNTW1LTYNIEyRN4DI0SYnnB4+fFjS0tKkT58+8vDDD8vx48evuW51dbVUVlY2WgBEnpbkDRu5AwhdAS8+RowYIcuXL5ctW7bIkiVLpKSkRL761a/K+fPnm1w/Ly9PEhMTG5b09PRADwlAkGtp3rCRO4DQFfDiY8KECXL//ffLoEGDJCsrSzZv3izl5eXy9ttvN7l+bm6uVFRUNCylpaWBHhKAINfSvGEjdwChq83P6OratavceOONcuTIkSbjXq/XWQCguXnDRu4AQlebFx8XLlyQo0ePyiOPPCJhw+NRwx0yeqnxj757vesuHrzrPTXet+MZNX70UrIaX7V3hBof8NNrT3fbfB8Uq3GxLD0ORFreQFDwVV1U44cux6jxO5KPqvH9lR3V+N2r/1nc9LMq1Hg4ZNeAf+zyve99T/Lz8+Xjjz+W9957T+69916Jjo6Whx56KNC7AhAmyBtAZAn4zMeJEyechHHu3Dnp0aOH3HHHHVJYWOj8PwA0hbwBRJaAFx+rV68O9CYBhDnyBhBZ+GI5AABgFMUHAAAwiuIDAAAYRfEBAACM4msjW9HH48yMUWr8uzm/VOOPxJdJm0s4qYZf/PsDanzF3+l9Ql5f9IAaT15c0K59QDwxsXq8o96cytNT//mlQu+DYvOVu1yrX13tug0AAearU8MfVOt9mNbk367G+9UUqvEbfv6puIqAPknMfAAAAKMoPgAAgFEUHwAAwCiKDwAAYBTFBwAAMIriAwAAGEXxAQAAjKL4AAAARkVmkzGXJmJRgwao8dk5b6vxh+JPuw1A/PWHar0JTZTHp8b/JjbKv5/B5Ri8+eEkNR7z2SXxR811HdX4J2P0JmPVqbVqfMygj9T43k8yxM2lY33UeObGy2rce1j/HdSe+MR1DAACy9dJb1Lmpq74SMDGEsqY+QAAAEZRfAAAAKMoPgAAgFEUHwAAwCiKDwAAYBTFBwAAMIriAwAAGBWRfT7OPDVKjc+eqfeweDj+jF99PF79rL/L80X+79axanzAT/QeD3VJCWrcerVCjW8e8B9+HYP73lws7SnOo/f58Ft6M9YZqYe/eEDv8/HLC3ovkbV36zuo/fi4PgAAV6mxotX4M1/dqMbXxuivW6tGf91HCmY+AACAURQfAADAKIoPAABgFMUHAAAwiuIDAAAYRfEBAACMovgAAABGhWWfj6jOndX45Ce3q/GH4k/71cfjVN1FNb459y6X7YvcmP+BGq+t0vfhcenz4a9oj163dvF0bNP911k+NV5t1apxn+jPN9FrxC3+QJcTavylnDQ13neu3gtGfHV6HIhAL+++x68+HxKl//uAVs587Nq1SyZOnChpaWni8Xhk/fr1jeKWZcm8efOkZ8+eEhcXJ+PGjZPDhw+3dDcAwgh5A4BfxUdVVZUMHjxYFi9uuoPl/PnzZeHChbJ06VLZs2ePdO7cWbKysuTSpUst3RWAMEHeAODXxy4TJkxwlqbY714WLFggzzzzjEyaNMl57K233pKUlBTnnc6UKVOuek51dbWz1KusrGzpkAAEuUDnDRu5AwhdAT3htKSkRMrKypwp03qJiYkyYsQIKSgoaPI5eXl5zjr1S3p6c740A0C4aE3esJE7gNAV0OLDTiA2+x3Llez79bEvy83NlYqKioaltLQ0kEMCEORakzds5A4gdLX71S5er9dZAKAlyB1A6ArozEdqaqpze/p040tV7fv1MQC4EnkDiDwBnfnIzMx0ksW2bdtkyJAhDSeB2WevT58+XUypGd5fjc9K+pkajxK9/8Lvq/WabebCuWo89f9d+3PselZ0tBr/U95wNb7igYVq/G9i3epOj199Ntq6j8jWL+LU+P+e/09qvEeRy8mJLj9eTZJ7H5OzM/VeLPuG/UKNez36y9OT5nIlSBv/jsItb6B5ouLj9XiCHq/95KQEs6gLeu79ZnyJGl9781h9B+/rPZwiRYuLjwsXLsiRI0canSx24MABSUpKkoyMDJk1a5a89NJLcsMNNzhJ5dlnn3Wu7c/Ozg702AGECPIGAL+Kj3379sldd/21Q+ecOXOc26lTp8ry5ctl7ty5zjX9TzzxhJSXl8sdd9whW7ZskY4d27bjJYDgRd4A4FfxMWbMGOe6/Guxuxe+8MILzgIANvIGgCvxxXIAAMAoig8AAGAUxQcAADCK4gMAAERWh9O2cOIuvethnEfv41ErdWr80Q1PqfEBvzymxutcenjYLmQPVeP/cu9KNT401n0f/jjn+0KN7/wiTY1/LU6/1v+6KL2Px23ez9R4wv369j2F+vatD/+kxjvU1oibtHM3qfG9v9Z7qYx0ad754M1FanxfB5efseayvgOEJY9LV9hT0/XcM3f6GjV+oCpDjR/8Wwlp0S49kNA8zHwAAACjKD4AAIBRFB8AAMAoig8AAGAUxQcAADCK4gMAABhF8QEAAIwKyz4f1am1fj2/xtL7fNywskrfQLRe0x1+5TbXMeR9Y5Uan9z5czVebenHYF1VTzX+wtsPqPGM3+h9PmIOlajxV7O/pcZfn7dYjY/06j0s3r15nRov2qD/jv+jQm9GsGrnaHF17e9Rc7xTOViND+9xQI1nej9V4/tE77eA0NOh1/Wu65z4Zm81PuPJ9Wr8f8T/To17Pfo/G+fr9G8iPig91DgiAzMfAADAKIoPAABgFMUHAAAwiuIDAAAYRfEBAACMovgAAABGUXwAAACjQrLPh6eDPuwHhv3Br+3HeKLVeMmkLvrzb/ap8YJhr7mOoVuU3sfic5/eZ2PioX9U43VrktV45ooiNW7VXNa3r0ZFkly2P+2mGWr8h9lvq/GsTsfV+NBY/fgO7fGfavz73/Tvb6w5f2dRosdrLD2O8MttS95b47qN66M7tes/C6/8dqIa7yeFEsms0UNc14muuKTGfYc+klDHzAcAADCK4gMAABhF8QEAAIyi+AAAAEZRfAAAAKMoPgAAgFEUHwAAwKiQ7PNh1daq8V9tH6nGX5qi95jo4NJf4dCji9R4lHjUuIjeY8JWdFnvlPHka/+sxlOW7lXjVu1RPS5ty61PSJ+nC9T4iryBavwn2Q+o8ew529X4E9ftV+PXufRhCQSfy2/h1Xf0fgp9ayK7n0I45rbCS9e7bmNy58/9yi0dPXr8lphYNR5T6Zb/ItvZp/UeTbbk50Lyn+a2nfnYtWuXTJw4UdLS0sTj8cj69esbxadNm+Y8fuVy9913B3LMAEIMeQOAX8VHVVWVDB48WBYvXnzNdeykcerUqYZl1apVLd0NgDBC3gBwpRbP7UyYMMFZNF6vV1JTU1u6aQBhirwBoM1PON25c6ckJydL//79Zfr06XLu3LlrrltdXS2VlZWNFgCRpyV5w0buAEJXwIsPe+r0rbfekm3btsnLL78s+fn5zjueurqmT2LKy8uTxMTEhiU9PT3QQwIQ5FqaN2zkDiB0BfyU2ilTpjT8/6233iqDBg2Svn37Ou9qxo4de9X6ubm5MmfOnIb79rsXkggQWVqaN2zkDiB0tXmfjz59+kj37t3lyJEj1/ycNyEhodECILK55Q0buQMIXW1+MfGJEyecz2579uwpptywrFyNr/pGihp/KP60Go/x6H1A6iyfGj9ee1HcTNn4v9R4/58fUOM+l34Boa6uvEKNJ/3iD2p8x9Hb1fgvvjtMjW8bvlTcxEfpL686lz4e6y709uvvXP8rDG7tkTdCwYEq/W+iOX0+HtowU43/IKvxZdBfdtH3iRrv+8YJNR7qmem8T/8JzvfrosZ/Nfg1131Mlycl3LW4+Lhw4UKjdyMlJSVy4MABSUpKcpbnn39eJk+e7Jy1fvToUZk7d67069dPsrKyAj12ACGCvAHAr+Jj3759ctdddzXcr//MderUqbJkyRI5ePCgvPnmm1JeXu40FBo/fry8+OKLzhQpgMhE3gDgV/ExZswYsaxrTxf/5je/aekmAYQ58gaAK/HFcgAAwCiKDwAAYBTFBwAAMIriAwAAhFefj/bgO/SRGv+3H0xW48nzl6vxr8d9ocZP1el9PB59ara46b/jv9S476J7r5BIZrn0OYn63ftqPKNAf2k81v8x1zH4Yv17eUV/6tLH44T+d47w89tFo13Xee6FIjVuRen9Ze7pfO3GbrbNVf3UeN1JvU9SqL8lT47upMa3L1ikxvdV68+3RZ+tCOteKTZmPgAAgFEUHwAAwCiKDwAAYBTFBwAAMIriAwAAGEXxAQAAjKL4AAAARoVlnw83nw7Ra67BsefU+Oc+jxq/Z//javz6HR+IG/p4BHefkLoPitt8DOFwLT8Cq/v+Std1aqw6NZ558yk1Hh+l/7MwtOMxNf6vr2Sr8Rt/rvevsT78k/gjOi1FjR/5di81vmrSQrc9qNEol/f0Oa/luGxfJLn0PQl3zHwAAACjKD4AAIBRFB8AAMAoig8AAGAUxQcAADCK4gMAABhF8QEAAIwKzz4fHr0Phwy4oIYTo2LV+NsX9OvEe/6rfljp4QGgvTzSq1CNv3bub9X4M90PqfGjDyxV49X31/jVp8RNjEfvw9HBpU+HWx+Pfz+fqsZXPP4NNZ78u/Dv4dEczHwAAACjKD4AAIBRFB8AAMAoig8AAGAUxQcAADCK4gMAABhF8QEAAIwKzz4flqWGvb+PV+OHhul9Qm72fqLGy0br20/9g0sfkmb8DAAiUHQzcoeLOkt/z7n3H/qq8Vtf0/uA7Bzxf9R4t6g4Nd7BpU9HrdT51Sfktc8GqvG31n9Njfd944Qajzr2vhpHK2Y+8vLyZNiwYRIfHy/JycmSnZ0txcXFjda5dOmSzJgxQ7p16yZdunSRyZMny+nTp1uyGwBhhtwBoNXFR35+vpMcCgsLZevWrVJTUyPjx4+XqqqqhnVmz54tGzdulLVr1zrrnzx5Uu67776W7AZAmCF3AGj1xy5btmxpdH/58uXOu5iioiK58847paKiQt544w1ZuXKlfO1rf566WrZsmdx0001O0hk5cmRLdgcgTJA7AATshFM7YdiSkpKcWzuR2O9oxo0b17DOgAEDJCMjQwoKCprcRnV1tVRWVjZaAIQ3cgcQ2VpdfPh8Ppk1a5aMHj1aBg788wk8ZWVlEhsbK127dm20bkpKihO71mfBiYmJDUt6enprhwQgBJA7ALS6+LA/vz106JCsXr3arwHk5uY674Lql9LSUr+2ByC4kTsAtOpS25ycHNm0aZPs2rVLevX669fLp6amyuXLl6W8vLzROxj7jHU71hSv1+ssAMIfuQNAi4sPy7Jk5syZsm7dOtm5c6dkZmY2ig8dOlRiYmJk27ZtzmVyNvtyuuPHj8uoUaOC5ohf/+45Nb7wwa+r8cUZ76jxN//n62p81v/PETfezfv0FegDghASLrmjvX38D3oPIVucJ1aN11gufTSO6TNIGVNOqfGHR85Q43+6r6Maj7mg9zKJ/1gNS2JJtb79vY0v8f6y3lVNn2NUr1bfPdqi+LCnS+2z0Tds2OBcr1//Waz9eWtcXJxz+9hjj8mcOXOcE8kSEhKchGMnD85WByIXuQNAq4uPJUuWOLdjxoxp9Lh9Sdy0adOc/3/99dclKirKefdin42elZUlP/vZz1qyGwBhhtwBwK+PXdx07NhRFi9e7CwAYCN3ALgSXywHAACMovgAAABGUXwAAACjKD4AAIBRFB8AACD4O5yGuroP9CYz577eWY0/eOO31XjUZb0NjffD/eKKJmIAvqTb8NN+b+OV305U4/2kUI1btXp+i9p9QN/+bmlXvvbdPf6CmQ8AAGAUxQcAADCK4gMAABhF8QEAAIyi+AAAAEZRfAAAAKMoPgAAgFER2efDja+qSl/h/Q/UcF1ghwMgQnTona7GX++/phlbiVajMZWeFo4KCDxmPgAAgFEUHwAAwCiKDwAAYBTFBwAAMIriAwAAGEXxAQAAjKL4AAAARtHnAwBMidJ7cJxb4lXjQ2P159vO1F1U433WfKbG6VMEE5j5AAAARlF8AAAAoyg+AACAURQfAADAKIoPAABgFMUHAAAwiuIDAAAEb5+PvLw8+fWvfy0fffSRxMXFye233y4vv/yy9O/fv2GdMWPGSH5+fqPnPfnkk7J06dLAjRpASCF3/IVP76JR+6se+tMHW667GLv3O2o8o/gj120AQTXzYSeGGTNmSGFhoWzdulVqampk/PjxUlVV1Wi9xx9/XE6dOtWwzJ8/P9DjBhBCyB0AWj3zsWXLlkb3ly9fLsnJyVJUVCR33nlnw+OdOnWS1NTUlmwaQBgjdwAI2DkfFRUVzm1SUlKjx1esWCHdu3eXgQMHSm5urly8eO12v9XV1VJZWdloARDeyB1AZGv1d7v4fD6ZNWuWjB492kkU9b71rW9J7969JS0tTQ4ePChPP/20FBcXO5/3Xuuz4Oeff761wwAQYsgdADyWZbmfwdSE6dOnyzvvvCO7d++WXr16XXO97du3y9ixY+XIkSPSt2/fJt+92Es9+91Lenq6jJFJ0sET05qhAfBTrVUjO2WDM0ORkJAQ0G2TO67t3GOj1HjBC4tctzG4YKoaz5iin3Bq1da67gPwN2+0auYjJydHNm3aJLt27VKTh23EiBHO7bUSiNfrdRYA4Y/cAaDFxYc9STJz5kxZt26d7Ny5UzIzM12fc+DAAee2Z8+eHHEgQpE7ALS6+LAvlVu5cqVs2LBB4uPjpayszHk8MTHRuXb/6NGjTvyee+6Rbt26OZ/bzp492zmbfdCgQS3ZFYAwQu5onh6r/lOND+o103UbX3lV34aPj1UQasXHkiVLGpoBXWnZsmUybdo0iY2NlXfffVcWLFjgXL9vf/46efJkeeaZZwI7agAhhdwBwK+PXTR2wvhyh0IAIHcAuBLf7QIAAIyi+AAAAEZRfAAAAKMoPgAAgFEUHwAAIDS+2wUAEFg+5Yv0bBnPv+e+jQCOB2grzHwAAACjKD4AAIBRFB8AAMAoig8AAGAUxQcAADCK4gMAAET2pbb1X0BVKzUi+ndRAWgjzuuvGV8IF0zIHUDo5I2gKz7Onz/v3O6Wze09FCDi2a/HxMRECQXkDiB08obHCrK3Nj6fT06ePCnx8fHi8XiksrLS+brt0tJSSUhIaO/hhSSOoX8i8fjZacFOIGlpaRIVFRqfzpI7Aovj579IO4ZWC/JG0M182APu1avXVY/bv7hI+OW1JY6hfyLt+IXKjEc9ckfb4Pj5L5KOYWIz80ZovKUBAABhg+IDAAAYFfTFh9frleeee865RetwDP3D8QtN/N78w/HzH8cwhE44BQAA4S3oZz4AAEB4ofgAAABGUXwAAACjKD4AAIBRFB8AAMCooC8+Fi9eLF/5ylekY8eOMmLECNm7d297Dylo7dq1SyZOnOi0trXbS69fv75R3L6wad68edKzZ0+Ji4uTcePGyeHDh9ttvMEmLy9Phg0b5rTnTk5OluzsbCkuLm60zqVLl2TGjBnSrVs36dKli0yePFlOnz7dbmNG08gbzUfe8A95IwyLjzVr1sicOXOc66T3798vgwcPlqysLDlz5kx7Dy0oVVVVOcfITrxNmT9/vixcuFCWLl0qe/bskc6dOzvH035hQCQ/P99JEIWFhbJ161apqamR8ePHO8e13uzZs2Xjxo2ydu1aZ337u0Tuu+++dh03GiNvtAx5wz/kjVaygtjw4cOtGTNmNNyvq6uz0tLSrLy8vHYdVyiwf7Xr1q1ruO/z+azU1FTrlVdeaXisvLzc8nq91qpVq9pplMHtzJkzznHMz89vOF4xMTHW2rVrG9b58MMPnXUKCgracaS4Enmj9cgb/iNvNE/QznxcvnxZioqKnCm+K784yr5fUFDQrmMLRSUlJVJWVtboeNpfAGRPSXM8m1ZRUeHcJiUlObf236P9rubKYzhgwADJyMjgGAYJ8kZgkTdajrzRPEFbfJw9e1bq6uokJSWl0eP2ffvFgJapP2Ycz+Z/PfusWbNk9OjRMnDgQOcx+zjFxsZK165dG63LMQwe5I3AIm+0DHmj+Tq0YF0gYtif4R46dEh2797d3kMBECLIG2Ew89G9e3eJjo6+6oxg+35qamq7jStU1R8zjqe7nJwc2bRpk+zYsUN69erV8Lh9nOxp/fLy8kbrcwyDB3kjsMgbzUfeCJPiw56mGjp0qGzbtq3RlJZ9f9SoUe06tlCUmZnp/KFfeTwrKyuds9c5nn9mn29nJ5B169bJ9u3bnWN2JfvvMSYmptExtC+pO378OMcwSJA3Aou84Y680UpWEFu9erVzVvXy5cutP/7xj9YTTzxhde3a1SorK2vvoQWl8+fPW++//76z2L/aH//4x87/Hzt2zIn/6Ec/co7fhg0brIMHD1qTJk2yMjMzrS+++KK9hx4Upk+fbiUmJlo7d+60Tp061bBcvHixYZ3vfOc7VkZGhrV9+3Zr37591qhRo5wFwYO80TLkDf+QN1onqIsP209/+lPnlxYbG+tcQldYWNjeQwpaO3bscJLHl5epU6c2XDb37LPPWikpKU5yHjt2rFVcXNzeww4aTR07e1m2bFnDOnbCfeqpp6zrrrvO6tSpk3Xvvfc6iQbBhbzRfOQN/5A3Wsdj/6e1syYAAABhc84HAAAITxQfAADAKIoPAABgFMUHAAAwiuIDAAAYRfEBAACMovgAAABGUXwAAACjKD4AAIBRFB8AAMAoig8AACAm/TdzvfR8DI4swwAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LTN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T12:07:59.884079Z",
     "start_time": "2025-05-06T12:07:59.753997Z"
    }
   },
   "source": [
    "logits_model = baselines.SingleDigit(inputs_as_a_list=True)\n",
    "\n",
    "# Digit = ltn.Predicate.FromLogits(logits_model, activation_function=\"softmax\")\n",
    "# FromLogits lets you override the scope name\n",
    "Digit = ltn.Predicate.FromLogits(\n",
    "    logits_model,\n",
    "    activation_function=\"softmax\",\n",
    "    name=\"softmaxDigit\"          # ← must begin with [A-Za-z0-9.]\n",
    ")\n",
    "\n",
    "\n",
    "d1 = ltn.Variable(\"digits1\", range(10))\n",
    "d2 = ltn.Variable(\"digits2\", range(10))\n",
    "\n",
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(),semantics=\"exists\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the use of `Diag`: when grounding $x$,$y$,$n$ with three sequences of values, the $i$-th examples of each variable are matching. \n",
    "That is, `(images_x[i],images_y[i],labels[i])` is a tuple from our dataset of valid additions.\n",
    "Using the diagonal quantification, LTN aggregates pairs of images and their corresponding result, rather than any combination of images and results. \n",
    "    \n",
    "Notice also the guarded quantification: by quantifying only on the \"intermediate labels\" (not given during training) that could add up to the result label (given during training), we incorporate symbolic information into the system."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T12:08:48.656469Z",
     "start_time": "2025-05-06T12:08:45.025781Z"
    }
   },
   "source": [
    "# mask\n",
    "add = ltn.Function.Lambda(lambda inputs: inputs[0]+inputs[1])\n",
    "equals = ltn.Predicate.Lambda(lambda inputs: inputs[0] == inputs[1])\n",
    "\n",
    "### Axioms\n",
    "@tf.function\n",
    "def axioms(images_x, images_y, labels_z, p_schedule=tf.constant(2.)):\n",
    "    images_x = ltn.Variable(\"x\", images_x)\n",
    "    images_y = ltn.Variable(\"y\", images_y)\n",
    "    labels_z = ltn.Variable(\"z\", labels_z)\n",
    "    axiom = Forall(\n",
    "            ltn.diag(images_x,images_y,labels_z),\n",
    "            Exists(\n",
    "                (d1,d2),\n",
    "                And(Digit([images_x,d1]),Digit([images_y,d2])),\n",
    "                mask=equals([add([d1,d2]), labels_z]),\n",
    "                p=p_schedule\n",
    "            ),\n",
    "            p=2\n",
    "        )\n",
    "    sat = axiom.tensor\n",
    "    return sat\n",
    "\n",
    "images_x, images_y, labels_z = next(ds_train.as_numpy_iterator())\n",
    "axioms(images_x, images_y, labels_z)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.01086127758026123>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, training steps and metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T12:08:49.561339Z",
     "start_time": "2025-05-06T12:08:49.520624Z"
    }
   },
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "metrics_dict = {\n",
    "    'train_loss': tf.keras.metrics.Mean(name=\"train_loss\"),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_loss': tf.keras.metrics.Mean(name=\"test_loss\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\")    \n",
    "}\n",
    "\n",
    "@tf.function\n",
    "def train_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    gradients = tape.gradient(loss, logits_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, logits_model.trainable_variables))\n",
    "    metrics_dict['train_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model([images_x]),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model([images_y]),axis=-1)\n",
    "    predictions_z = predictions_x + predictions_y\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['train_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    metrics_dict['test_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model([images_x]),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model([images_y]),axis=-1)\n",
    "    predictions_z = predictions_x + predictions_y\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['test_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T12:08:50.577220Z",
     "start_time": "2025-05-06T12:08:50.568293Z"
    }
   },
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "scheduled_parameters = defaultdict(lambda: {})\n",
    "for epoch in range(0,4):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(1.)}\n",
    "for epoch in range(4,8):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(2.)}\n",
    "for epoch in range(8,12):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(4.)}\n",
    "for epoch in range(12,20):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(6.)}"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T12:09:41.680745Z",
     "start_time": "2025-05-06T12:08:51.131039Z"
    }
   },
   "source": [
    "commons.train(\n",
    "    20,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    scheduled_parameters=scheduled_parameters\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 0.9373, train_accuracy: 0.3700, test_loss: 0.8639, test_accuracy: 0.8046\n",
      "Epoch 1, train_loss: 0.8565, train_accuracy: 0.8467, test_loss: 0.8495, test_accuracy: 0.8790\n",
      "Epoch 2, train_loss: 0.8444, train_accuracy: 0.9026, test_loss: 0.8443, test_accuracy: 0.8978\n",
      "Epoch 3, train_loss: 0.8394, train_accuracy: 0.9232, test_loss: 0.8397, test_accuracy: 0.9286\n",
      "Epoch 4, train_loss: 0.6436, train_accuracy: 0.9269, test_loss: 0.6426, test_accuracy: 0.9157\n",
      "Epoch 5, train_loss: 0.6302, train_accuracy: 0.9425, test_loss: 0.6287, test_accuracy: 0.9444\n",
      "Epoch 6, train_loss: 0.6204, train_accuracy: 0.9568, test_loss: 0.6229, test_accuracy: 0.9514\n",
      "Epoch 7, train_loss: 0.6172, train_accuracy: 0.9631, test_loss: 0.6220, test_accuracy: 0.9544\n",
      "Epoch 8, train_loss: 0.4276, train_accuracy: 0.9571, test_loss: 0.4434, test_accuracy: 0.9236\n",
      "Epoch 9, train_loss: 0.4151, train_accuracy: 0.9634, test_loss: 0.4255, test_accuracy: 0.9425\n",
      "Epoch 10, train_loss: 0.4065, train_accuracy: 0.9714, test_loss: 0.4169, test_accuracy: 0.9534\n",
      "Epoch 11, train_loss: 0.4009, train_accuracy: 0.9741, test_loss: 0.4110, test_accuracy: 0.9623\n",
      "Epoch 12, train_loss: 0.3157, train_accuracy: 0.9721, test_loss: 0.3486, test_accuracy: 0.9385\n",
      "Epoch 13, train_loss: 0.3148, train_accuracy: 0.9724, test_loss: 0.3232, test_accuracy: 0.9573\n",
      "Epoch 14, train_loss: 0.3007, train_accuracy: 0.9804, test_loss: 0.3090, test_accuracy: 0.9712\n",
      "Epoch 15, train_loss: 0.2979, train_accuracy: 0.9801, test_loss: 0.3253, test_accuracy: 0.9583\n",
      "Epoch 16, train_loss: 0.2975, train_accuracy: 0.9817, test_loss: 0.3251, test_accuracy: 0.9554\n",
      "Epoch 17, train_loss: 0.3015, train_accuracy: 0.9797, test_loss: 0.3207, test_accuracy: 0.9623\n",
      "Epoch 18, train_loss: 0.2964, train_accuracy: 0.9827, test_loss: 0.3230, test_accuracy: 0.9603\n",
      "Epoch 19, train_loss: 0.2913, train_accuracy: 0.9850, test_loss: 0.3286, test_accuracy: 0.9544\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T12:08:01.628164Z",
     "start_time": "2025-05-06T12:08:01.628164Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12eaedf9b9a64329743e8900a3192e3d75dbaaa78715534825922e4a4f7d9137"
  },
  "kernelspec": {
   "display_name": "Python environment",
   "language": "python",
   "name": "environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
