{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Addition Problem\n",
    "\n",
    "Consider a task where one needs to learn a classifier $\\mathtt{addition(X,Y,N)}$ where $\\mathtt{X}$ and $\\mathtt{Y}$ are images of digits (the MNIST data set will be used), and $\\mathtt{N}$ is a natural number corres"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "ponding to the sum of these digits. The classifier should return an estimate of the validity of the addition ($0$ is invalid, $1$ is valid). \n",
    "\n",
    "For instance, if $\\mathtt{X}$ is an image of a 0 and $\\mathtt{Y}$ is an image of a 9:\n",
    "- if $\\mathtt{N} = 9$, then the addition is valid; \n",
    "- if $\\mathtt{N} = 4$, then the addition is not valid. \n",
    "\n",
    "A natural approach is to seek to first 1) learn a single digit classifier, then 2) benefit from knowledge readily available about the properties of addition.\n",
    "For instance, suppose that a predicate $\\mathrm{digit}(x,d)$ gives the likelihood of an image $x$ being of digit $d$, one could query with LTN:    \n",
    "$$\n",
    "\\exists d_1,d_2 : d_1+d_2= \\mathtt{N} \\ (\\mathrm{digit}(\\mathtt{X},d_1)\\land \\mathrm{digit}(\\mathtt{Y},d_2))\n",
    "$$\n",
    "and use the satisfaction of this query as the output of $\\mathtt{addition(X,Y,N)}$ .\n",
    "\n",
    "\n",
    "The challenge is the following:\n",
    "- We provide, in the data, pairs of images $\\mathtt{X}$, $\\mathtt{Y}$ and the result of the addition $\\mathtt{N}$ (final label),\n",
    "- We do **not** provide the intermediate labels, the correct digits for $d_1$, $d_2$.\n",
    "\n",
    "Regardless, it is possible to use the equation above as background knowledge to train $\\mathrm{digit}$ with LTN.\n",
    "In contrast, a standard neural network baseline cannot incorporate such intermediate components as nicely."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:46:51.439802Z",
     "start_time": "2025-05-06T09:46:51.433689Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "import baselines, data, commons\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Dataset of images for the digits X and Y, and their label Z s.t. X+Y=Z."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:46:53.555478Z",
     "start_time": "2025-05-06T09:46:51.494327Z"
    }
   },
   "source": [
    "op_sub = lambda args: tf.cast(args[0], tf.int32) - tf.cast(args[1], tf.int32)\n",
    "\n",
    "ds_train, ds_test = data.get_mnist_op_dataset(\n",
    "        count_train=3000,\n",
    "        count_test=1000,\n",
    "        buffer_size=3000,\n",
    "        batch_size=16,\n",
    "        n_operands=2,\n",
    "        op=op_sub)\n",
    "\n",
    "# Visualize one example\n",
    "x, y, z = next(ds_train.as_numpy_iterator())\n",
    "plt.subplot(121)\n",
    "plt.imshow(x[0][:,:,0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(y[0][:,:,0])\n",
    "print(\"Result label is %i\" % z[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result label is -3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LTN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:46:53.580327Z",
     "start_time": "2025-05-06T09:46:53.557735Z"
    }
   },
   "source": [
    "logits_model = baselines.SingleDigit(inputs_as_a_list=True)\n",
    "\n",
    "# Digit = ltn.Predicate.FromLogits(logits_model, activation_function=\"softmax\")\n",
    "# FromLogits lets you override the scope name\n",
    "Digit = ltn.Predicate.FromLogits(\n",
    "    logits_model,\n",
    "    activation_function=\"softmax\",\n",
    "    name=\"softmaxDigit\"          # ← must begin with [A-Za-z0-9.]\n",
    ")\n",
    "\n",
    "\n",
    "d1 = ltn.Variable(\"digits1\", range(10))\n",
    "d2 = ltn.Variable(\"digits2\", range(10))\n",
    "\n",
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(),semantics=\"exists\")"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the use of `Diag`: when grounding $x$,$y$,$n$ with three sequences of values, the $i$-th examples of each variable are matching. \n",
    "That is, `(images_x[i],images_y[i],labels[i])` is a tuple from our dataset of valid additions.\n",
    "Using the diagonal quantification, LTN aggregates pairs of images and their corresponding result, rather than any combination of images and results. \n",
    "    \n",
    "Notice also the guarded quantification: by quantifying only on the \"intermediate labels\" (not given during training) that could add up to the result label (given during training), we incorporate symbolic information into the system."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:46:59.603540Z",
     "start_time": "2025-05-06T09:46:57.559669Z"
    }
   },
   "source": [
    "# mask\n",
    "subtract = ltn.Function.Lambda(lambda inputs: inputs[0]-inputs[1])\n",
    "equals = ltn.Predicate.Lambda(lambda inputs: inputs[0] == inputs[1])\n",
    "\n",
    "### Axioms\n",
    "@tf.function\n",
    "def axioms(images_x, images_y, labels_z, p_schedule=tf.constant(2.)):\n",
    "    images_x = ltn.Variable(\"x\", images_x)\n",
    "    images_y = ltn.Variable(\"y\", images_y)\n",
    "    labels_z = ltn.Variable(\"z\", labels_z)\n",
    "    axiom = Forall(\n",
    "            ltn.diag(images_x,images_y,labels_z),\n",
    "            Exists(\n",
    "                (d1,d2),\n",
    "                And(Digit([images_x,d1]),Digit([images_y,d2])),\n",
    "                mask=equals([subtract([d1,d2]), labels_z]),\n",
    "                p=p_schedule\n",
    "            ),\n",
    "            p=2\n",
    "        )\n",
    "    sat = axiom.tensor\n",
    "    return sat\n",
    "\n",
    "images_x, images_y, labels_z = next(ds_train.as_numpy_iterator())\n",
    "axioms(images_x, images_y, labels_z)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.010373413562774658>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, training steps and metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:47:03.163283Z",
     "start_time": "2025-05-06T09:47:03.136343Z"
    }
   },
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "metrics_dict = {\n",
    "    'train_loss': tf.keras.metrics.Mean(name=\"train_loss\"),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_loss': tf.keras.metrics.Mean(name=\"test_loss\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\")    \n",
    "}\n",
    "\n",
    "@tf.function\n",
    "def train_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    gradients = tape.gradient(loss, logits_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, logits_model.trainable_variables))\n",
    "    metrics_dict['train_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model([images_x]),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model([images_y]),axis=-1)\n",
    "    predictions_z = predictions_x - predictions_y\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['train_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    metrics_dict['test_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model([images_x]),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model([images_y]),axis=-1)\n",
    "    predictions_z = predictions_x - predictions_y\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['test_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:47:05.522476Z",
     "start_time": "2025-05-06T09:47:05.511300Z"
    }
   },
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "scheduled_parameters = defaultdict(lambda: {})\n",
    "for epoch in range(0,4):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(1.)}\n",
    "for epoch in range(4,8):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(2.)}\n",
    "for epoch in range(8,12):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(4.)}\n",
    "for epoch in range(12,20):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(6.)}"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:48:00.171566Z",
     "start_time": "2025-05-06T09:47:07.678134Z"
    }
   },
   "source": [
    "commons.train(\n",
    "    20,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    scheduled_parameters=scheduled_parameters\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 0.9438, train_accuracy: 0.3421, test_loss: 0.9303, test_accuracy: 0.4097\n",
      "Epoch 1, train_loss: 0.9126, train_accuracy: 0.5126, test_loss: 0.9143, test_accuracy: 0.5228\n",
      "Epoch 2, train_loss: 0.8997, train_accuracy: 0.5947, test_loss: 0.9106, test_accuracy: 0.5516\n",
      "Epoch 3, train_loss: 0.8841, train_accuracy: 0.6779, test_loss: 0.8914, test_accuracy: 0.6468\n",
      "Epoch 4, train_loss: 0.7230, train_accuracy: 0.7480, test_loss: 0.7537, test_accuracy: 0.6667\n",
      "Epoch 5, train_loss: 0.7141, train_accuracy: 0.7613, test_loss: 0.7446, test_accuracy: 0.6905\n",
      "Epoch 6, train_loss: 0.7092, train_accuracy: 0.7709, test_loss: 0.7358, test_accuracy: 0.7103\n",
      "Epoch 7, train_loss: 0.6555, train_accuracy: 0.8946, test_loss: 0.6716, test_accuracy: 0.8651\n",
      "Epoch 8, train_loss: 0.4421, train_accuracy: 0.9405, test_loss: 0.4833, test_accuracy: 0.8849\n",
      "Epoch 9, train_loss: 0.4386, train_accuracy: 0.9441, test_loss: 0.4782, test_accuracy: 0.8919\n",
      "Epoch 10, train_loss: 0.4237, train_accuracy: 0.9581, test_loss: 0.4741, test_accuracy: 0.8948\n",
      "Epoch 11, train_loss: 0.4176, train_accuracy: 0.9634, test_loss: 0.4790, test_accuracy: 0.8889\n",
      "Epoch 12, train_loss: 0.3406, train_accuracy: 0.9535, test_loss: 0.4096, test_accuracy: 0.8909\n",
      "Epoch 13, train_loss: 0.3261, train_accuracy: 0.9641, test_loss: 0.3818, test_accuracy: 0.9137\n",
      "Epoch 14, train_loss: 0.3141, train_accuracy: 0.9724, test_loss: 0.3943, test_accuracy: 0.9028\n",
      "Epoch 15, train_loss: 0.3122, train_accuracy: 0.9727, test_loss: 0.3770, test_accuracy: 0.9187\n",
      "Epoch 16, train_loss: 0.3063, train_accuracy: 0.9751, test_loss: 0.3786, test_accuracy: 0.9097\n",
      "Epoch 17, train_loss: 0.3147, train_accuracy: 0.9714, test_loss: 0.3860, test_accuracy: 0.9087\n",
      "Epoch 18, train_loss: 0.3039, train_accuracy: 0.9787, test_loss: 0.3784, test_accuracy: 0.9147\n",
      "Epoch 19, train_loss: 0.3054, train_accuracy: 0.9774, test_loss: 0.3808, test_accuracy: 0.9167\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12eaedf9b9a64329743e8900a3192e3d75dbaaa78715534825922e4a4f7d9137"
  },
  "kernelspec": {
   "display_name": "Python environment",
   "language": "python",
   "name": "environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
